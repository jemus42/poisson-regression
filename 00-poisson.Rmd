---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Das Poisson-Modell {#mod-pois}

Das *Poisson*-Modell ist die allgemeine Grundlage für die Modellierung von Zählvorgängen / Counts, und auch wenn es in seiner "reinen" Form in der Praxis meist nicht ausreicht, bauen alle weiteren Methoden auf die eine oder andere Art darauf auf. Auch die häufig verwendete *Negative Binomialverteilung* ist letztlich eine *Poisson*-Verteilung mit *Gamma*-verteilter Varianz, also eine Erweiterung der *Poisson* um einen zusätzlichen Parameter. Das gleiche Prinzip findet sich in allen hier besprochenen Verteilungen. 

Für eine ausführliche Diskussion der Eigenschaften, siehe @winkelmannEconometricAnalysisCount2010 (p. 7-20).

Grundlage zur Modellierung ist das GLM mit den dazugehörigen Voraussetzungen:

- Die abhängige Variable $Y$ kommt aus der Exponentialfamilie (Normal-, Poisson-, Gamma-, Binomialverteilung)
- Modelliert wird der lineare Prädiktor $\eta_i = \boldsymbol{x}_i' \boldsymbol{\beta}$.
- Response- und Linkfunktionen $h(x)$ und $g(x) = h^{-1}(x)$ 


```{definition, name = "Poisson-Verteilung"}
Eine Poisson-verteilte Zufallsvariable $Y \sim \mathrm{Poi}(\lambda)$ [^poiparam] hat die Dichte

\begin{equation*}
\mathrm{P}(Y = y) = \frac{\lambda^y \exp(-\lambda)}{y!} \quad, y \in \mathbb{N}_0
\end{equation*}
```

```{r poisson_dists, echo=FALSE}
map_df(c(0.5, 1, 2, 5, 10, 15), ~{
  tibble(
    lambda = .x,
    x = 0:20,
    poi = dpois(x, lambda)
  )
}) %>%
  ggplot(aes(x = x, y = poi, color = factor(lambda), fill = factor(lambda))) +
  geom_path(aes(group = lambda), linetype = "dotted") +
  geom_point(shape = 21, color = "black", size = 2.5, stroke = .2) +
  #geom_segment(aes(x = x, xend = x, y = 0 , yend = poi)) +
  scale_color_viridis_d(direction = -1, guide = FALSE) +
  scale_fill_viridis_d(
    direction = -1, guide = guide_legend(
      keywidth = .5,
      nrow = 1,
      direction = "horizontal"
      )
  ) +
  labs(
    title = expression(Poi(lambda)),
    x = "y", y = expression(Poi(y, lambda)), fill = expression(lambda)
  ) +
  theme(legend.position = c(.7, .9))
```

```{definition, name = "Poisson-Modell"}
Die Zielvariablen $y_i \in \mathbb{N}_0$ sind (bedingt) unabhängig gegeben der Kovariablen $x_i1, x_i2, \ldots, x_ik$.

Die Rate $\lambda_i = \mathbb{E}(y_i\ |\ \mathbf{x}_i)$ der Poissonverteilung wird in der Regel log-linear modelliert als

\begin{align*}
  \log(\lambda_i) &= \eta_i 
    = \mathbf{x}_i^\prime \boldsymbol{\beta} 
    = \beta_0 + \beta_1 x_1 + \ldots + \beta_k x_{ik} \\
  \lambda_i &= \exp(\eta_i) 
    = \exp(\beta_0) \cdot \exp(\beta_1 x_1) \cdot \ldots \cdot \exp(\beta_k x_k)
\end{align*}

```


[^poiparam]: Der Poisson-Parameter wird von unterschiedlichen Autoren als $\lambda$ oder $\mu$ bezeichnet, und ich habe mich noch nicht für eine Variante entschieden).


Vgl. @fahrmeirRegressionModelleMethoden2009

Für das log-lineare Poisson-Modell entsprechen die resultierenden Koeffizienten der Veränderung der log-counts – durch Exponentiation lassen diese sich als *incidence rate ratios* (*IRR*) interpretieren.

## Annahmen

1. Die Abhängige / Zielvariable $Y$ muss eine Zählung sein, i.e. die Verteilung ist diskret mit einem einzelnen Parameter $\lambda$ der Poisson-Verteilung für Erwartungswert und Varianz.
2. $y \in \mathbb{N}_0$, insbesondere: $Y$ muss 0 enthalten *können* (siehe auch \@ref(trunc-cens) [Truncation und Censoring](#trunc-cens))
3. Beobachtungen sind *unabhängig*, i.e. weder longitudinal noch gepoolt.
   - Möglicher Test durch Vergleich der Modell-SE und der SE adjustiert durch:
   - 1. Robuste sandwich-estimators
   - 2. Bootstrapped SEs
   - 3. SE skaliert mit der $\chi^2$-Dispersionsstatistik: $se \cdot \sqrt{\chi^2}$
   - Große Unterschiede implizieren korrelierte Daten
4. Balanced: Die Zellen sind in etwa so besetzt wie es aufgrund der Poissonverteilung erwartet wird.
5. Erwartungswert und Varianz sind identisch (*equidispersion*), i.e. ein größerer Erwartungswert impliziert auch eine größere Varianz.
6. Die $\chi^2$-Statistik hat einen Wert nahe 1, i.e. beobachtete und erwartete Varianzen der response sind gleich (Dispersionsindex)
   - Check auf overdispersion: Boundary likelihood ratio test

(Nach Tabelle in [@hilbeModelingCountData2014], braucht noch Deduplizierung)

Alternative Formulierung nach @winkelmannEconometricAnalysisCount2010 (p. 64):

1. $f(y\ |\ \lambda) = \frac{e^{-\lambda} \lambda^y}{y!} \quad \lambda > 0, y = 0, 1, 2, \ldots$.
2. $\lambda = \exp(\mathbf{x}' \boldsymbol{\beta})$.
3. Beobachtungspaare $(y_i, x_i)$ sind unabhängig verteilt.

## Offset

Ein Offset wird benötigt, um auf ungleiche Expositionsdauern oder -gebiete zu adjustieren. Dazu dient der Koeffizient $t$, der die Länge der Zeit unter Exposition angibt:

\begin{equation}
f(y, \mu) = \frac{\exp(\mu) (t \mu)^y}{y!}
\end{equation}

Damit entspricht $t \mu$ der Inzidenzrate des Outcomes adjustiert auf e.g. die geographische Lage oder Expositionsdauer. Ohne Offset entspräche $t = 1$.
Für als Offset wird in der Regel $\log(t)$ verwendet, womit gelten:

\begin{align*}
\hat{\lambda} &= \exp{x \boldsymbol{\beta} + \log(t)} \\
\Leftrightarrow \exp(x \boldsymbol{\beta}) &= \frac{\hat{\lambda}}{t} \\
\Leftrightarrow \hat{\lambda} &= t \exp(x \boldsymbol{\beta})
\end{align*}

Ein offset kann z.B. in `R` via `+ offset(log(variable))` in der model `formula` oder über das Argument `offset = log(variable)` in `glm` und verwandten Funktionen angegeben werden.


## Dispersion {#dispersion}

```{definition, name = "Equi-, Extra-, Over-, Underdispersion"}
Für Zählvariablen $y_i \in \mathbb{N}_0$ und erklärenden Variablen $\mathbf{x}_i$ gilt innerhalb eines Modells:

\begin{align*}
\text{Equdispersion:}  \quad & \mathrm{Var}(y_i) = \mathrm{Var}(y_i\ |\ \mathbf{x}_i) \\
\text{Extradispersion:}\quad & \mathrm{Var}(y_i) \neq \mathrm{Var}(y_i\ |\ \mathbf{x}_i) \\
\text{Overdispersion:} \quad & \mathrm{Var}(y_i) > \mathrm{Var}(y_i\ |\ \mathbf{x}_i) \\
\text{Underdispersion:}\quad & \mathrm{Var}(y_i) < \mathrm{Var}(y_i\ |\ \mathbf{x}_i)
\end{align*}

```


```{definition, name = "Poisson-Overdispersion"}
Innerhalb eines Poisson-Modells (vgl. Abschnitt \@ref(mod-pois)) mit der Annahme

\begin{align*}
y_i\ |\ \mathbf{x}_i &\sim \mathrm{Poi}(\lambda_i) \\[1.5em]
\lambda_i &= \mathbb{E}(y_i\ |\ \mathbf{x}_i) = \mathrm{Var}(y_i\ |\ \mathbf{x}_i) \quad \text{(Equidispersion)}
\end{align*}

spricht man von **Poisson-Overdispersion** wenn die Varianz der Beobachtungen die erwartete Varianz des Poisson-Modells übersteigt:

\begin{equation*}
  \mathrm{Var}(y_i\ |\ \mathbf{x}_i) > \mathbb{E}(y_i\ |\ \mathbf{x}_i)
\end{equation*}

in einem Modell mit overdispersion gilt die Annahme:

\begin{equation*}
  \mathrm{Var}(y_i\ |\ \mathbf{x}_i) = \theta \cdot \lambda_i
\end{equation*}

Mit *Dispersionsparameter* $\theta$ [vgl. @fahrmeirRegressionModelleMethoden2009, p. 210]

```


Als Dispersionsstatistik können *deviance dispersion* oder *Pearson dispersion* berechnet werden. Laut @hilbeModelingCountData2014 ist die *Pearson dispersion* zu bevorzugen, da sie für echte Poisson-Modelle gleich 1 ist, wohingegen die *deviance dispersion* nach oben verzerrt ist.


```{definition pearsondisp, name = "Pearson-Dispersion"}
Nach @hilbeModelingCountData2014 (p. 77ff):

Die Pearson $\chi^2$-Statistik definiert als die Summe der quadriertern (Pearson-)Residuen gewichtet mit der Modellvarianz:

\begin{equation*}
\chi_{\text{Pearson}}^2 = \sum_{i=1}^n \frac{(y_i - \hat{\mu}_i)^2}{\mathrm{Var}(\hat{\mu}_i)}
\end{equation*}

und die **Pearson-Dispersionsstatistik**:
  
\begin{equation*}
D = \frac{\chi_{\text{Pearson}}^2}{\mathrm{df}}
\end{equation*}

Mit der Interpretation

\begin{equation*}
\mathrm{Dispersion} =
  \begin{cases}
    < 1 & \Longrightarrow \text{Underdispersion} \\
      1 & \Longrightarrow \text{Equidispersion (Poisson)} \\
    > 1 & \Longrightarrow \text{Overdispersion}
  \end{cases}
\end{equation*}

Für Modelle moderater Größe kann man ab Werten über 1.25 von ovderdispersion reden, wobei für große Stichproben auch schon ab 1.05 overdispersion vorliegen kann – zumindest nach @hilbeModelingCountData2014 (p. 82), der aber leider keine konkreten Zahlen für seine Definition von "moderaten" oder "großen" Stichproben nennt.
```

In `R` kann die Pearson-Dispersion wie folgt berechnet werden:

```r
# Model fit
mod <- glm(y ~ x1 + x2 + x3, data = sim, family = poisson(link = "log"))

# Pearson dispersion
sum(resid(mod, type = "pearson")^2) / mod$df.residual
```

...wofür wir in Abschnitt \@ref(helperfuns) eine Hilfsfunktion `dispersion()` definiert haben.

## Anwendungsbeispiel

```{r poisson-example-fast}
data(fasttrakg, package = "COUNT")

ggplot(fasttrakg, aes(x = die)) +
  geom_bar() +
  labs(title = "'fasttrakg'",
       x = "Todesfälle", y = "Count")

mod_fast <- glm(die ~ anterior + hcabg + factor(killip), 
           family = poisson(), offset = log(cases),
           data = fasttrakg)

pander(mod_fast)
pander(glance(mod_fast))
```


(Kopiert aus Abschnitt Annahmen/Overdispersion, not sure where to put:)

Als Beispiel verwenden wir hier ein Subset des Datensatz `rwm5yr` (vgl. Abschnitt \@ref(data), `?COUNT::rwm5yr`), der Angaben zur Anzahl der Arztbesuche pro Person mit zusätzlichen demographischen Merkmalen enthält. Für unser Beispielmodell verwenden wir folgende Variablen:

- `docvis`: Abhängige Variable, Anzahl der Arztbesuche im Jahr (0-121)
- `outwork`: Arbeitslos (1), arbeitend (0)
- `age`: Alter (25 - 64)

```{r poisson-example-rwm}
# Daten + subsetting
data(rwm5yr, package = "COUNT")
rwm1984 <- subset(rwm5yr, year == 1984)

# Model fit
mod_rwm <- glm(docvis ~ outwork + age, family = poisson(), data = rwm1984)

pander(mod_rwm)

pander(glance(mod_rwm))
```
