---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Mehrparametrische Modelle {#multiparam}

```{r model-graph, echo=FALSE}
grViz(readLines("graphs/model-graph.dot"))
```


Zweiparametrische Modelle haben neben dem Parameter für den Erwartungswert einen weiteren Parameter für die Dispersion, was wir natürlich insbesondere im Kontext der Dispersionsproblematik sehr nützlich finden.  
Alle hier aufgeführten Modelle (inklusive der zero-inflation models) können als Verallgemeinerung der Poisson-Verteilung um (mindestens) einen weiteren Parameter aufgefasst werden. Die Unterschiede liegen hauptsächlich in der Parametrisierung und den damit zusammenhängenden Einschränkungen. Die *Negative Binomialverteilung* und die *Poisson Inverse Gaussian* zum Beispiel erweitern beide die Poisson um einen Dispersionsparameter, machen aber unterschiedliche Annahmen zur Verteilung der Varianz (gamma- vs. invers-normalverteilt).  

Tabelle \@ref(tab:modelstable) zeigt eine Reihe von Verteilungen mit entsprechend parametrisierter Varianz abhängig vom Erwartungswert $\mu$ und einem Dispersionsparameter $\alpha$.

```{r modelstable, echo=FALSE}
tibble::tribble(
  ~Model,                         ~Mean,  ~Variance,
  "Poisson",                     "$\\mu$", "$\\mu$",
  "Negative Binomial I (NB1)",   "$\\mu$", "$\\mu (1 + \\alpha) = \\mu + \\alpha\\mu$",
  "Negative Binomial II (NB2)",  "$\\mu$", "$\\mu (1 + \\alpha\\mu) = \\mu + \\alpha\\mu^2$",
  "Negative Binomial-P (NBP)",   "$\\mu$", "$\\mu (1 + \\alpha\\mu^p) = \\mu + \\alpha\\mu^p$",
  "Poisson Inverse Gaussian (PIG)", "$\\mu$", "$\\mu (1 + \\alpha\\mu^2) = \\mu + \\alpha\\mu^3$",
  "Generalized Poisson (GP)",    "$\\mu$", "$\\mu (1 + \\alpha\\mu)^2 = \\mu + 2\\alpha\\mu^3 + \\alpha^2\\mu^3$"
 ) %>%
  kable(booktabs = TRUE, escape = FALSE, linesep = "",
        caption = " Ein Überblick einiger Modelle mit Varianzparametrisierung (nach @hilbeModelingCountData2014, p. 12).") %>%
  kable_styling(position = "center", protect_latex = FALSE)
```


## Negativ Binomial (NB) {#mod-nb}

Die Negative Binomialverteilung (*NB*) kann als zweiparametrische Erweiterung der *Poisson* betrachtet werden, wobei die Varianz (separat vom Erwartungswert) als Gamma-verteilte Zufallsvariable betrachtet wird (*Poisson-Gamma Mischmodell*). 

```{definition, name = "Negative Binomialverteilung"}
Nach @perumean-chaneyZeroinflatedOverdispersedWhat2013 (p. 1675):

Für $Y \sim NB(\mu, \theta)$ gilt
  
\begin{equation}
P(Y = y) = \frac{\Gamma(\theta + y)}{\Gamma(\theta) \Gamma(y+1)} \frac{\theta^\theta \mu^y}{(\theta + \mu)^{(\theta + y)}}, \quad y = 0, 1, 2, \ldots
\end{equation}

Mit $\mathbb{E}(Y) = \mu$ und $\mathrm{Var}(Y) = \mu + \frac{\mu^2}{\theta}$
  
```


Der gängigste Anwendungsfall der *NB* findet sich bei Daten mit nicht korrigierbarer overdispersion (siehe Abschnitt \@ref(overdispersion)), da der Parameter $\theta$ bzw. auch $\alpha = \frac 1 \theta$ als *Dispersionsparameter* dient:


```{definition nbdisppar, name = "NB-Dispersionsparameter"}

Meist wird der Parameter als $\theta$ bezeichnet, mit der Interpretation (relativ zum Poisson-Modell):

\begin{align}
  \theta &> 0 &&\Longrightarrow \text{ Overdispersion} \\
  \theta &\to \infty &&\Longrightarrow \text{ Äquivalent zur Poissonverteilung}
\end{align}

Je nach Quelle (und unter Anderem in R (z.B. `MASS::glm.nb`)) wird die inverse Variante $\alpha = \frac 1 \theta$ verwendet, womit gilt:

$$\mathrm{Var}(Y) = \mu + \alpha \mu^2$$
  
\begin{align}
  \alpha &= 0 &&\Longrightarrow \text{ Äquivalent zur Poissonverteilung} \\
  \alpha &> 0 &&\Longrightarrow \text{ Overdispersion}
\end{align}

Die Interpretation (und numerische Handhabung) könnte dementsprechend der Grund für die Präferenz von $\alpha$ sein.

```

(Vgl. @hilbeModelingCountData2014, @hilbe2011NegativeBinomial)


Der wohl wichtigste Aspekt des Dispersionsparameters, unabhängig davon ob $\alpha$ oder $\theta$ verwendet wird, ist sein Vorzeichen: Er ist _immer_ positiv, das heißt die Varianz der NB ist entweder _größer oder gleich_ der Poisson, oder mit anderen Worten:

> "The negative binomial model adjusts for Poisson overdispersion; it **cannot be used to model underdispersed** Poisson data" 
>
> --- [@hilbeModelingCountData2014 (p. 11), eigene Hervorhebung]


- Interpretation der exponentierten Koeffizienten: IRRs
- Zwei Varianten: NB1, NB2


## Poisson Inverse Gaussian (PIG) {#mod-pig}

So wie die *NB* als mixture aus Poisson-Verteilung mit Gamma-verteilter Varianz betrachtet werden kann, ist die *Poisson Inverse Gaussian* (*PIG*) eine mixture aus Poisson-Verteilung mit [invers-normalverteilter](https://en.wikipedia.org/wiki/Inverse_Gaussian_distribution) Varianz. Demnach kann man *PIG* als Alternative zur *NB* verwenden.


- Dispersionsparameter $\alpha$, Interpretation analog NBIN
- Interpretation der exponentierten Koeffizienten: IRRs

- Software:
- R: `gamlss` (CRAN)
- Stata: `pigreg`

## Generalized Poisson (GP) {#mod-gp}

- Auch mit dispersion/scale Parameter $\alpha$
- Analog NB: $\alpha = 0 \Rightarrow y \sim \mathrm{Pois}(\lambda)$
- Selling feature: $\alpha < 0$ ist möglich, im Gegensatz zu NB
- -> Underdispersion modellierbar

- Software: 
- [Vgl. Stackexchange Kommentar von Joseph Hilbe](https://stats.stackexchange.com/a/237177/80056)
- R: [`VGAM`](https://rdrr.io/cran/VGAM/man/genpoisson.html)


## Conway-Maxwell Poisson (COMP) {#mod-comp}

```{definition, name = "Conway-Maxwell-Poisson Modell (CMP)"}
Nach @shmueli2005UsefulDistribution (p. 129):
  
\begin{align}
P(X = x) &= \frac{\lambda^x}{(x!)^\nu} \frac{1}{Z(\lambda, \nu)}, \quad x = 0, 1, 2, \ldots \\
Z(\lambda, \nu) &= \sum_{j = 0}^\infty \frac{\lambda^j}{(j!)^\nu} \\
\\
\lambda > 0&, \nu \ge 0
\end{align}

Mit (im Unterschied zur Poisson) nichtlinearer Zerfallsrate $\nu$ *rate of decay*, so dass:

\begin{equation}  
\frac{P(X = x -1)}{P(X = x)} = \frac{x^\nu}{\lambda}
\end{equation}

Der Zusammenhang zwischen $\nu$ und $\lambda$ nach @sellers2010FlexibleRegression (p. 946) legt Nahe, dass $\nu$ ähnlich $\alpha$ in NB-Modellen die Dispersion bestimmt:
  
\begin{align*}
  \mathrm{Var}(Y_i) =& \lambda_i \frac{\partial}{\partial \lambda_i} \mathbb{E}(Y_i)
            \approx \lambda_i \frac{\partial}{\partial \lambda_i} \left( \lambda_i^{\frac{1}{\nu}} - \frac{\nu - 1}{2 \nu} \right) \\
                  =& \frac{1}{\nu} \lambda^{\frac{1}{\nu}}
           \approx \frac{1}{\nu} \mathbb{E}(Y_i)
\end{align*}
```

Die Verteilung hat als Spezialfälle:

- $\nu = 1 \Longrightarrow Z(\lambda, \nu) = exp(\lambda)$: Poisson
- $\nu \to \infty \Longrightarrow Z(\lambda, \nu) \to 1 + \lambda$: Bernoulli mit $P(X = 1) = \frac{\lambda}{1+\lambda}$
- $\nu = 0,\ \lambda < 1$: Geometrisch mit $P(X = x) = \lambda^x (1 - \lambda)$


**Vorteile**:

- "Brücke" zwischen logistischer und Poisson-Regression [@sellers2010FlexibleRegression]

> Although the logistic regression is a limiting case $(\nu \to \infty)$, in practice, fitting a COM-Poisson regression to binary data yields estimates and predictions that are practically identical to those from a logistic regression.
>
> --- @sellers2010FlexibleRegression, p. 945

- "Low cost", i.e. "nur" ein zusätzlicher Parameter
- Einfach zu handhaben (wenn in GLM mit MLE statt MCMC estimation)
- Over- und underdispersion abbildbar
- Zero-inflation abbildbar

**Software**:

- `CompGLM::glm.comp`
- `COMPoissonReg` (GitHub: `lotze/COMPoissonReg`)
- `compoisson` (Not sure if modelling)


Siehe auch

- @sellers2010FlexibleRegression für eine gute Übersicht
- @lord2010ExtensionApplication, @lord2008ApplicationConwayMaxwellPoisson für eine Anwendung
- @shmueli2005UsefulDistribution


# Weitere Modelle

## Diagnostische Modelle

### Heterogenous Negative Binomial (NBH) {#mod-nbh}

- Selling feature: Erlaubt Parametrisierung von $\alpha$
- -> Ursache für under-/overdispersion modellierbar

### Negative binomial-P (NB-P) {#mod-nbp}

- NB: Varianz statisch für alle Beobachtungen
- -> NB-P: Varianz kann für Beobachtungen variieren (Parameter $\rho$)

- Primärer Anwendungsfall: Bestimmen, ob NB1 oder NB2 besser passt
  - Wenn $\rho \approx 2$ -> NB2, sonst NB1 (@hilbeModelingCountData2014, p. 21)


## Zero-Inflated Models (*mixture models*) {#mod-zi}

- Logit/Probit Komponente für zeros
   - Unterschied: Modelliert Nullen im Gegensatz zu Einsen
- Binary zeros und count zeros werden durch beide Komponenten modelliert 
   - -> Nicht getrennt interpretierbar
- -> Erzeugen eigene PDF, e.g. ZIP, die mixture aus beiden Komponenten darstellt


ZIP und ZINB wurde hergeleitet als zweiteilige mixture distributions. Die allgemeine Form für mixture distributions ist

\begin{equation*}
  P(Y = y) = p \cdot g_1(y) + (1-p) \cdot g_2(y)
\end{equation*}

mit $p$ als *mixture proportion* und $g_1, g_2$ als Dichte-/Massefunktionen der beiden Komponenten.

In dieser Darstellung entspricht $p$ der *rate of zero-inflation* $\pi$, $g_1$ einer degenerierten 0-Verteilung und $g_2$ einer Poisson-PMF.

```{definition defzip, name = "Zero-Inflated Poisson Verteilung (ZIP)"}
Nach @perumean-chaneyZeroinflatedOverdispersedWhat2013 (p. 1675)

\begin{align*}
P(Y = 0) &= \pi + (1-\pi) \cdot e^{-\mu} \\
P(Y = y) &= (1 - \pi) \cdot \frac{\mu^y e^{-\mu}}{y!}, \quad y = 1, 2, 3, \ldots
\end{align*}
```

```{definition defzinb, name = "Zero-Inflated Negative Binomialverteilung (ZINB)"}
Nach @perumean-chaneyZeroinflatedOverdispersedWhat2013 (p. 1675)

\begin{align*}
P(Y = 0) &= \pi + (1 - \pi) \cdot \frac{\theta^\theta}{(\theta + \mu)^\theta}  \\
P(Y = y) &= (1 - \pi) \cdot \frac{\Gamma(\theta+y)}{\Gamma(\theta) \Gamma(y + 1)} \frac{\theta^\theta \mu^y}{(\theta + \mu)^{(\theta + y)}}, \quad y = 1, 2, 3, \ldots
\end{align*}
```


Die ZI-Modelle sind dabei **geschachtelt** mit ihren ursprünglichen Modellen, da sich letzteres für bestimmte $\pi$ aus dem ZI-Modell ergeben.  
Dieser Umstand ist Teil der Kritik an der Verwendung des Vuong-Test (entworfen für den Vergleich von  _**un**geschachtelten_ Modellen) von @wilson2015MisuseVuong, der sich gegen die Verwendung des Tests ausspricht um die Modellanpassung von Modellen mit ihren ZI-Gegenstücken zu vergleichen (siehe z.B. @perumean-chaneyZeroinflatedOverdispersedWhat2013 für eine solche Anwendung des Vuong-Tests).
