# (APPENDIX) Appendix {-} 

# Verfügbarkeit

Sowohl der Quelltext als auch das Output (sprich, dieses Dokument in mehreren Formaten) sind öffentlich an mehreren Orten zu finden:

```{r availibility, echo=FALSE}
tibble::tribble(
  ~" ", ~Host, ~URL,
  "Code", "Gitea (self-hosted)", "https://git.tadaa-data.de/lukas/poisson-regression",
  "Code", "GitHub", "https://github.com/jemus42/poisson-regression",
  "Result", "GitHub Pages", "https://jemus42.github.io/poisson-regression",
  "Result", "Self-Hosted", "https://lukas.tadaa-data.de/poisson/"
) %>%
  kable(booktabs = TRUE) %>%
  kable_styling(position = "center", bootstrap_options = c("hover")) %>%
  collapse_rows(columns = 1)
```


# Ergänzungen

Hier finden sich Erläuterungen zu Themen, die nur tangentiell in Verbindung mit dem eigentlichen Thema stehen, aber unter Umständen dennoch von Interesse sein könnten.

## Missing values und missingness patterns {#appendix-missingness}

Zu den Begriffen im Kontext von missingness wird folgende Unterscheidung bezüglich der Verteilung der missing values für eine Variable $Y$ gemacht (vgl. auch @littleStatisticalAnalysisMissing2002, p. 12):

- **MCAR** (missing completely at random): Das Fehlen eines Wertes in $Y$ ist völlig unabhängig von sowohl beobachteten als auch unbeobachtet Daten. Dieser Fall wäre der idealzustand, ist allerdings in der Regel weder realistisch noch verifizierbar.
- **MAR** (missing at random): Es gibt einen Zusammenhang zwischen Ausfallwahrscheinlichkeit und *beobachteten* Daten. Das heißt auch, dass missingness durch beobachtete Daten erklärt werden kann, weshalb dieser Fall noch akzeptabel wäre.
- **MNAR** / **NMAR** (missing not at random): Weder *MCAR* noch *MAR* – die Ausfallwahrscheinlichkeit hängt von *unbeobachten* Daten ab. Das heißt, es gibt ein Ausfallmuster in $Y$, das nicht durch vorliegende Daten erklärt werden kann, wodurch in der Regel verzerrte Effektschätzungen entstehen.

## Truncation und Censoring {#trunc-cens}

Wenn die Beobachtungen keine Nullen enthalten bzw. im Modell aus inhaltlichen Gründen nicht möglich sind, können *zero-truncated* (ZT) Modelle verwendet werden. Diese Modelle sind insbesondere im Kontext von *hurdle models* interessant (siehe Abschnitt \@ref(mod-hurdle)), in denen die positiven counts getrennt von den Null-counts modelliert werden. Eine *truncated* distribution wäre die zero-truncated Poisson (ZTP).

Bemerke, dass *truncation* hier etwas anderes meint als *censoring*:

**Truncation** bedeutet, dass bestimmte counts (i.e. Merkmalsausprägungen in $Y$) _nicht möglich_ sind. Als Beispiel könnte die Dauer eines Krankenhausaufenthalts dienen, da Aufenthaltstage erst ab einem Tag aufgezeichnet werden. (siehe auch Datensatz `azprocedure`, \@ref(data)).  
Unterschieden werden kann zwischen *left truncation* (z.B. keine counts kleiner als 5), *right truncation* (analog, keine counts größer als 5), oder *interval truncation* (nur counts im Intervall $[2, 10]$).

**Censoring** wiederum bedeutet, dass eine Merkmalsausprägung (wie etwa $Y = 0$ oder auch $Y = 1029$) zwar im Modell prinzipiell möglich ist, aber lediglich nicht in einer konkreten Stichprobe beobachtet wurde.

## Hurdle models {#mod-hurdle}

Im Falle von **binären Outcomes** ist es fraglich plausibel hurdle models anzuwenden, da in diesem Fall die Nullen und die Einsen separat modelliert würden – normalerweise würde man die Nullen durch ein logit- und die positiven Counts durch ein Poisson(ähnliches) Modell beschreiben wollen, was aber natürlich für binäre Outcomes entsprechend schwierig wäre.  
Die nachfolgende Beschreibung dient daher eher der Vollständigkeit, insbesondere da hurdle models in bestimmten Anwendungsgebieten scheinbar recht populär sind.

Im Allgemeinen kann man zwei Arten von hurdle models unterscheiden, die jjeweils aus zwei Modellkomponenten bestehen:

- *Nested* hurdle models: Beide Komponenten nested (e.g. beide Poisson).
- *Non-nested* hurdle models: Hurdle-Komponente als vollständig anderer Prozess betrachtet und via e.g. logit modelliert.

Zwei gängige Komponenten für unnested hurdle models:

1. Binary 0,1 response, (logit oder probit)
   - Modellierung der Wahrscheinlichkeit für die non-zero counts
2. Zero-truncated count model

- Erlauben sowohl under- als auch overdispersion
- (Unnested models) erlauben systematischen Unterschied im Prozess, der zu e.g. Outcomes = 0 vs. Outcomes > 0 führt, was durch die Wahl unterschiedlicher Modelle für beide Komponenten abgebildet wird

In diesem Fall entspricht das Resultat eines hurdle models zwei separat gefitteten Modellen (e.g. Pois + Logit), die getrennt interpretierbar sind (im Gegensatz zu zero-inflated models!).

```{definition, name = "Hurdle Model"}
Nach @winkelmannEconometricAnalysisCount2010, p. 179f:
  
Sei $g_1(0)$ die Wahrscheinlichkeit des Outcomes $0$ und $g_1(k), k = 1, 2, 3, \ldots$ die Wahrscheinlichkeitsfunktion für natürliche Zahlen, dann ist die Wahrscheinlichkeitsfunktion eines *hurdle-at-zero* Modells:
  
\begin{align*}
f(y = 0) &= g_1(0) \\
f(y = k) &= (1 - g_1(0)) g_2(k), \quad k = 1, 2, 3, \ldots
\end{align*}

Bzw. nach @mullahy1986SpecificationTesting mit $f_1$ und $f_2$ als PMFs für natürliche Zahlen

\begin{align*}
f(y = 0) &= f_1(0) \\
f(y = 1) &= \frac{1 - f_1(0)}{1 - f_2(0)} f_2(k) \\
         &= \Theta f_2(k), \quad k = 1, 2, 3, \ldots 
\end{align*}

Wobei 

- $f_2$ als *parent process* bezeichnet wird
- $1 - f_1(0)$ die Wahrscheinlichkeit angibt, die Hürde ($y = 0$) zu "überqueren" (*"crossing the hurdle"*).
- $1 - f_2(0)$ zur Normalisierung von $f_2$ dient, um deren truncation zu berücksichtigen.

Der Erwartungswert des hurdle models ist

$$
  \mathbb{E}_h(y) = \Theta \sum_{k=1}^\infty k f_2(k) = \Theta \mathbb{E}_2(y)
$$
  
Mit $\mathbb{E}_2$ als Erwartunsgwert von $f_2$.

Mit $f_2 = \mathrm{Poisson}$:
  
- $0 < \Theta < 1$: Overdispersion  
- $1 < \Theta < \frac{\lambda_2 + 1}{\lambda_2}$: Underdispersion

```


> "By far the most popular hurdle model in practice is the hurdle-at-zero negative bonomial model"
[@winkelmannEconometricAnalysisCount2010, p. 183]

mit $f_1 \sim NB(\beta_1, \alpha_1)$ und $f_2 \sim NB(\beta_2, \alpha_2)$

# Reproduzierbarkeit {#repro}

## R-Code 

Hier verwendeter Code profitiert stark vom [`tidyverse`](https://www.tidyverse.org/).  
Insbesondere wird anstelle der Funktion `data.frame` in der Regel `tibble` (package `tibble`, automatisch re-exportiert von `dplyr`) verwendet. Diese Alternative bietet einige quality of life improvements für schnelle Simulationen, zum Beispiel die Verwendung von Variablen während diese noch definiert werden:

```{r df_tibble, eval=FALSE}
# Nicht möglich:
data.frame(
   x1 = rnorm(10),
   x2 = rnorm(10, mean = 5),
   y = 50 + 3 * x1 + 5 * x2
)

# Funktioniert!
tibble(
   x1 = rnorm(10),
   x2 = rnorm(10, mean = 5),
   y = 50 + 3 * x1 + 5 * x2
)
```

Zusätzlich kann die Pipe (`%>%`) Verwendung finden, ein function composition operator.  
Es gilt:

`f(g(h(x), b = 4), a = 1)` = `h(x) %>% g(b = 4) %>% f(a = 1)`


```{r pipe, eval=FALSE}
# Klassisch
x <- rnorm(100, mean = 15)
x_mean <- mean(x)
sqrt(x_mean)

# oder
sqrt(mean(rnorm(100, mean = 15)))

# piped
rnorm(100, mean = 15) %>%
   mean() %>%
   sqrt()

# Klassisch
iris_subset <- subset(iris, Species == "setosa")
head(iris_subset[order(iris_subset$Sepal.Length, decreasing = TRUE), ], n = 5)

# tidyverse-style (incl. filter() als subset()-Analog und top_n() für order() + head())
iris %>%
   filter(Species == "setosa") %>%
   top_n(Sepal.Length, n = 5)
```

Letztlich stellt das Package [`broom`](https://broom.tidyverse.org/) eine wichtige Ergänzung dar. Mitunter ist [`augment()`](https://broom.tidyverse.org/reference/augment.lm.html#examples) eine komfortable Möglichkeit um schnell in tabellarischer Form gefittete Werte mit ihren dazugehörigen x-Werten zu erhalten.

## Session Info

```{r sessioninfo, echo=FALSE}
sinfo <- sessioninfo::session_info()[c("platform", "packages")]

sinfo$platform %>%
  unclass() %>%
  as_tibble() %>%
  t() %>%
  as_tibble(rownames = "m", .name_repair = make.names) %>%
  setNames(c("Umgebungsvariable", "Wert")) %>%
  kable(booktabs = TRUE, linesep = "") %>%
  kable_styling(position = "center")

sinfo$packages %>%
  filter(attached) %>%
  select(package, loadedversion, source) %>%
  setNames(c("Package", "Version", "Quelle")) %>%
  kable(booktabs = TRUE, linesep = "") %>%
  kable_styling(position = "center")


# list(
#   sinfo$platform %>% 
#   unclass() %>%
#   as_tibble() %>% 
#   t() %>% 
#   as_tibble(rownames = "m", .name_repair = make.names) %>%
#   setNames(c("Umgebungsvariable", "Wert")),
#   sinfo$packages %>%
#   filter(attached) %>%
#   select(package, loadedversion, source) %>%
#   setNames(c("Package", "Version", "Quelle")) 
# ) %>%
#   kable(booktabs = TRUE, linesep = "") %>%
#   kable_styling(position = "center")
```


## Unsorted

Hier liegen temporär Opfer der Umstrukturierung, bis sie ein passendes zu Hause gefunden haben, oder auf die farm upstate umziehen.

### General Advice

- Starte mit einem Poisson-Modell und baue darauf auf
- Benutze robuste Varianzschätzer (e.g. sandwich, Bootstrap-SEs sind meist den Aufwand nicht wert) – entweder sie helfen, oder sie schaden nicht.
- Das gängigste Problem ist overdispersion, aber nicht jede overdispersion ist gleich.
- Die erwartete Anzahl an Nullen (unter Poisson) ist $\exp(-\bar{x}) \cdot n$

### Beispiel nach @hilbeModelingCountData2014, p. 211ff

(Eigentlich kompliziertes Beispiel, weil 0 counts nicht möglich sind, müsste man truncated drangehen)

Grundlage ist der Datensatz `azprocedure` (siehe Abschnitt \@ref(data)) zur Dauer des Krankenhausaufenthalts.

Zuerst werfen wir einen Blick auf die Daten und fitten ein reguläres Poissonmodell.

```{r underdisp-azprocedure-over}
data(azprocedure, package = "COUNT")

describe_counts(azprocedure$los)

# Barchart: So grob poissonverteilt?
ggplot(data = azprocedure, aes(x = los)) +
  geom_bar(alpha = .75) +
  labs(
    title = "Hospital length of stay (LOS)",
    subtitle = "azprocedure data (Hilbe 2014)",
    x = "LOS", y = "Count" 
  )

# Model fit
model_azproc <- glm(los ~ procedure + sex + admit, 
                    data = azprocedure, family = poisson())
 
# Model output (ohne exponentierte Koeffizienten)
pander(model_azproc)

# Pearson Dispersion:
dispersion(model_azproc)
```

Der Dispersionsindex lässt auf overdispersion schließen.  
Betrachten wir ein Subset der Daten, indem wir nur Beobachtungen mit $\mathtt{LOS} \le 8$ betrachten, erhalten wir ein anderes Bild:

```{r underdisp-azprocedure_under}
azprocedure_subset <- subset(azprocedure, los <= 8)

describe_counts(azprocedure_subset$los)

# Barchart
ggplot(data = azprocedure_subset, aes(x = los)) +
  geom_bar(alpha = .75) +
  labs(
    title = "Hospital length of stay (LOS)",
    subtitle = "Subset (LOS <= 8) der azprocedure data (Hilbe 2014)",
    x = "LOS", y = "Count" 
  )

model_azproc_u <- glm(los ~ procedure + sex + admit, 
                      data = azprocedure_subset, family = poisson())

pander(model_azproc_u)
dispersion(model_azproc_u)
```

In diesem Fall haben wir es mit underdispersion zu tun, also versuchen wir es mal mit der GP:

```{r underdisp-azprocedure-gpois}
library(VGAM)
library(gamlss)

mod_gp_vgam <- vglm(los ~ procedure + sex + admit, data = azprocedure_subset, family = genpoisson())

mod_gp_gamlss <- gamlss(los ~ procedure + sex + admit, data = azprocedure_subset, family = GPO())

summary(mod_gp_vgam)
summary(mod_gp_gamlss)
```

Beispiel aus Hilbe 2014. Eigentlich sollte $\delta \approx -0.1195$ und $\theta = \frac{1}{(1 - \delta)^2} \approx 0.799$

