---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Modelle {#modelle}

Ein Überblick einiger Modelle mit parametrisierter Varianz (nach @hilbeModelingCountData2014, p. 12).

```{r models_table_1, echo=FALSE}
tibble::tribble(
  ~Model,                         ~Mean,  ~Variance,
  "Poisson",                     "$\\mu$", "$\\mu$",
  "Negative Binomial (NB1)",     "$\\mu$", "$\\mu (1 + \\alpha) = \\mu + \\alpha\\mu$",
  "Negative Binomial (NB2)",     "$\\mu$", "$\\mu (1 + \\alpha\\mu) = \\mu + \\alpha\\mu^2$",
  "Poisson Inverse Gaussian (PIG)", "$\\mu$", "$\\mu (1 + \\alpha\\mu^2) = \\mu + \\alpha\\mu^3$",
  "Negative binomial-P (NBP)",   "$\\mu$", "$\\mu (1 + \\alpha\\mu^p) = \\mu + \\alpha\\mu^p$",
  "Generalized Poisson (GP)",    "$\\mu$", "$\\mu (1 + \\alpha\\mu)^2 = \\mu + 2\\alpha\\mu^3 + \\alpha^2\\mu^3$"
 ) %>%
  kable(booktabs = TRUE, escape = FALSE, linesep = "") %>%
  kable_styling(position = "center", protect_latex = TRUE)
```

## Zweiparametrische Modelle

## Negative Binomial (NB) {#mod-nb}

```{definition, name = "Negative Binomialverteilung"}
Nach @perumean-chaneyZeroinflatedOverdispersedWhat2013 (p. 1675):

Für $Y \sim NB(\mu, \theta)$ gilt
  
\begin{equation}
P(Y = y) = \frac{\Gamma(\theta + y)}{\Gamma(\theta) \Gamma(y+1)} \frac{\theta^\theta \mu^y}{(\theta + \mu)^{(\theta + y)}}, \quad y = 0, 1, 2, \ldots
\end{equation}

Mit $\mathbb{E}(Y) = \mu$ und $\mathrm{Var}(Y) = \mu + \frac{\mu^2}{\theta}$
```


- Derivation: Poisson-Gamma Mischmodell
- Erweiterung der Poissonverteilung um einen Dispersionsparameter $\alpha$
  - Wenn $\alpha > 0$: overdispersion
  - Wenn $\alpha = 0$: Äquivalent zu Poisson
- Interpretation der exponentierten Koeffizienten: IRRs
- Zwei Varianten: NB1, NB2
- Software Pitfalls:
  - Dispersionsparameter in R's `glm` bzw. `MASS::glm.nb` invertiert: $\theta = \frac 1 \alpha$
  - -> Äquivalenz zu Poisson bei $\theta \to \infty$
  
> "The negative binomial model adjusts for Poisson overdispersion; it **cannot be used to model underdispersed** Poisson data" 
> [@hilbeModelingCountData2014, p. 11]
  
Vgl @hilbeModelingCountData2014

### Poisson Inverse Gaussian (PIG) {#mod-pig}

- Annahme: Overdispersion besser über *inverse Gaussian* Verteilung als Gamma-Verteilung (siehe NBIN) beschreibbar

- Dispersionsparameter $\alpha$, Interpretation analog NBIN
- Interpretation der exponentierten Koeffizienten: IRRs

- Software:
- R: `gamlss` (CRAN)
- Stata: `pigreg` ()

### Generalized Poisson {#mod-gp}

- Auch mit dispersion/scale Parameter $\alpha$
- Analog NB: $\alpha = 0 \Rightarrow y \sim \mathrm{Pois}(\lambda)$
- Selling feature: $\alpha < 0$ ist möglich, im Gegensatz zu NB
- -> Underdispersion modellierbar

- Software: 
- [Vgl. Stackexchange Kommentar von Joseph Hilbe](https://stats.stackexchange.com/a/237177/80056)
- R: [`VGAM`](https://rdrr.io/cran/VGAM/man/genpoisson.html)


### Heterogenous Negative Binomial (NBH) {#mod-nbh}

- Selling feature: Erlaubt Parametrisierung von $\alpha$
- -> Ursache für under-/overdispersion modellierbar

### Negative binomial-P (NB-P) {#mod-nbp}

- NB: Varianz statisch für alle Beobachtungen
- -> NB-P: Varianz kann für Beobachtungen variieren (Parameter $\rho$)

- Primärer Anwendungsfall: Bestimmen, ob NB1 oder NB2 besser passt
  - Wenn $\rho \approx 2$ -> NB2, sonst NB1 (@hilbeModelingCountData2014, p. 21)


## Dreiparametrische Modelle


### Conway-Maxwell Poisson {#mod-comp}

```{definition, name = "Conway-Maxwell-Poisson Modell (CMP)"}
Nach @shmueli2005UsefulDistribution (p. 129):
  
\begin{align}
P(X = x) &= \frac{\lambda^x}{(x!)^\nu} \frac{1}{Z(\lambda, \nu)}, \quad x = 0, 1, 2, \ldots \\
Z(\lambda, \nu) &= \sum_{j = 0}^\infty \frac{\lambda^j}{(j!)^\nu} \\
\\
\lambda > 0&, \nu \ge 0
\end{align}

Mit nichtlinearer Zerfallsrate $\nu$ *rate of decay*, so dass:

\begin{equation}  
\frac{P(X = x -1)}{P(X = x)} = \frac{x^\nu}{\lambda}
\end{equation}
```

Die Verteilung hat als Spezialfälle:

- $\nu = 1 \Longrightarrow Z(\lambda, \nu) = exp(\lambda)$: Poisson
- $\nu \to \infty \Longrightarrow Z(\lambda, \nu) \to 1 + \lambda$: Bernoulli mit $P(X = 1) = \frac{\lambda}{1+\lambda}$
- $\nu = 0,\ \lambda < 1$: Geometrisch mit $P(X = x) = \lambda^x (1 - \lambda)$


- **Vorteile**:
- "Low cost", i.e. "nur" ein zusätzlicher Parameter
- Einfach zu handhaben
- Over- und underdispersion abbildbar
- Zero-inflation abbildbar

- Software:
   - `CompGLM::glm.comp`
   - `COMPoissonReg` (GitHub: `lotze/COMPoissonReg`)
   - `compoisson` (Not sure if modelling)

## Zero-Inflated Models (*mixture models*) {#mod-zi}

- Logit/Probit Komponente für zeros
   - Unterschied: Modelliert Nullen im Gegensatz zu Einsen
- Binary zeros und count zeros werden durch beide Komponenten modelliert 
   - -> Nicht getrennt interpretierbar
- -> Erzeugen eigene PDF, e.g. ZIP, die mixture aus beiden Komponenten darstellt

Beispiel: Poisson-logit hurdle Modell, bestehend aus logit-Modell für zeros und zero-truncated Poisson für die non-zero counts

ZIP und ZINB wurde hergeleitet als zweiteilige mixture distributions. Die allgemeine Form für mixture distributions ist

\begin{equation}
  P(Y = y) = p \cdot g_1(y) + (1-p) \cdot g_2(y)
\end{equation}

mit $p$ als *mixture proportion* und $g_1, g_2$ als Dichte-/Massefunktionen der beiden Komponenten.

In dieser Darstellung entspricht $p$ der *rate of zero-inflation* $\pi$, $g_1$ einer degenerierten 0-verteilung und $g_2$ einer Poisson-PMF.

```{definition, name = "Zero-Inflated Poisson Verteilung (ZIP)"}
Nach @perumean-chaneyZeroinflatedOverdispersedWhat2013 (p. 1675)

\begin{align}
P(Y = 0) &= \pi + (1-\pi) \cdot e^{-\mu} \\
P(Y = 1) &= (1 - \pi) \cdot \frac{\mu^y e^{-\mu}}{y!}
\end{align}
```

```{definition, name = "Zero-Inflated Negative Binomialverteilung (ZINB)"}
Nach @perumean-chaneyZeroinflatedOverdispersedWhat2013 (p. 1675)

\begin{align}
P(Y = 0) &= \pi + (1 - \pi) \cdot \frac{\theta^\theta}{(\theta + \mu)^\theta}  \\
P(Y = 1) &= (1 - \pi) \cdot \frac{\Gamma(\theta+y)}{\Gamma(\theta) \Gamma(y + 1)} \frac{\theta^\theta \mu^y}{(\theta + \mu)^{(\theta + y)}}
\end{align}
```

## Hurdle models {#mod-hurdle}

- *Nested* hurdle models: Beide Komponenten nested (e.g. beide Poisson).
- *Non-nested* hurdle models: Hurdle-Komponente als vollständig anderer Prozess betrachtet und via e.g. logit modelliert.

Zwei Komponenten für unnested hurdle models:

1. Binary 0,1 response, (logit oder probit)
   - Modellierung der Wahrscheinlichkeit für die non-zero counts
2. Zero-truncated count model

- Erlauben sowohl under- als auch overdispersion
- (Unnested models) erlauben systematischen Unterschied im Prozess, der zu e.g. Outcomes = 0 vs. Outcomes > 0 führt, was durch die Wahl unterschiedlicher Modelle für beide Komponenten abgebildet wird

In diesem Fall entspricht das Resultat eines hurdle models zwei separat gefitteten Modellen (e.g. Pois + Logit), die getrennt interpretierbar sind (im Gegensatz zu zero-inflated models!).

```{definition, name = "Hurdle Model"}
Nach @winkelmannEconometricAnalysisCount2010, p. 179f:
  
Sei $g_1(0)$ die Wahrscheinlichkeit des Outcomes $0$ und $g_1(k), k = 1, 2, 3, \ldots$ die Wahrscheinlichkeitsfunktion für natürliche Zahlen, dann ist die Wahrscheinlichkeitsfunktion eines *hurdle-at-zero* Modells:
  
\begin{align*}
f(y = 0) &= g_1(0) \\
f(y = k) &= (1 - g_1(0)) g_2(k), \quad k = 1, 2, 3, \ldots
\end{align*}

Bzw. nach @mullahy1986SpecificationTesting mit $f_1$ und $f_2$ als PMFs für natürliche Zahlen

\begin{align*}
f(y = 0) &= f_1(0) \\
f(y = 1) &= \frac{1 - f_1(0)}{1 - f_2(0)} f_2(k) \\
         &= \Theta f_2(k), \quad k = 1, 2, 3, \ldots 
\end{align*}

Wobei 

- $f_2$ als *parent process* bezeichnet wird
- $1 - f_1(0)$ die Wahrscheinlichkeit angibt, die Hürde ($y = 0$) zu "überqueren" (*"crossing the hurdle"*).
- $1 - f_2(0)$ zur Normalisierung von $f_2$ dient, um deren truncation zu berücksichtigen.

Der Erwartungswert des hurdle models ist

$$
  \mathbb{E}_h(y) = \Theta \sum_{k=1}^\infty k f_2(k) = \Theta \mathbb{E}_2(y)
$$
  
Mit $\mathbb{E}_2$ als Erwartunsgwert von $f_2$.

Mit $f_2 = \mathrm{Poisson}$:
  
- $0 < \Theta < 1$: Overdispersion  
- $1 < \Theta < \frac{\lambda_2 + 1}{\lambda_2}$: Underdispersion

```


> "By far the most popular hurdle model in practice is the hurdle-at-zero negative bonomial model"
[@winkelmannEconometricAnalysisCount2010, p. 183]

mit $f_1 \sim NB(\beta_1, \alpha_1)$ und $f_2 \sim NB(\beta_2, \alpha_2)$


Im Falle von **binären Outcomes** ist es fraglich plausibel hurdle models anzuwenden, da in diesem Fall die Nullen und die Einsen durch separate Modelle modelliert würden.

