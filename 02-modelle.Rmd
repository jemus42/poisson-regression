---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Modelle 

Ein Überblick einiger Modelle mit parametrisierter Varianz (nach @hilbeModelingCountData2014, p. 12).

```{r models_table_1, echo=FALSE}
tibble::tribble(
  ~Model,                         ~Mean,  ~Variance,
  "Poisson",                     "$\\mu$", "$\\mu$",
  "Negative Binomial (NB1)",     "$\\mu$", "$\\mu (1 + \\alpha) = \\mu + \\alpha\\mu$",
  "Negative Binomial (NB2)",     "$\\mu$", "$\\mu (1 + \\alpha\\mu) = \\mu + \\alpha\\mu^2$",
  "Poisson Inverse Gamma (PIG)", "$\\mu$", "$\\mu (1 + \\alpha\\mu^2) = \\mu + \\alpha\\mu^3$",
  "Negative binomial-P (NBP)",   "$\\mu$", "$\\mu (1 + \\alpha\\mu^p) = \\mu + \\alpha\\mu^p$",
  "Generalized Poisson (GP)",    "$\\mu$", "$\\mu (1 + \\alpha\\mu)^2 = \\mu + 2\\alpha\\mu^3 + \\alpha^2\\mu^3$"
 ) %>%
  kable(booktabs = TRUE, escape = FALSE, linesep = "") %>%
  kable_styling(position = "center", protect_latex = TRUE)
```

## Poisson {#mod-pois}

Das Poisson-Modell stellt die Grundlage für die meisten der folgenden Modelle dar, und verdient daher eine genauere Betrachtung.

```{definition, name = "Poisson-Modell"}
Eine Poisson-verteilte Zufallsvariable $Y \sim \mathrm{Poi}(\lambda)$ [^poiparam] hat die Dichte

\begin{equation}
f(y\ |\ \lambda) = \mathrm{P}(Y = y) = \frac{\lambda^y \exp(-\lambda)}{y!} \quad, y \in \mathbb{N}_0
\end{equation}

Die Rate $\lambda_i = \mathbb{E}(y_i | x_i)$ der Poissonverteilung wird in der Regel log-linear modelliert als

\begin{equation}
\log(\lambda_i) = \eta_i = \mathbf{x}_i^\prime \boldsymbol{\beta} = \beta_0 + \beta_1 x_1 + \ldots + \beta_k x_{ik}
\end{equation}

mit der regulären Form:

\begin{equation}
\lambda_i = \exp(\eta_i) = \exp(\beta_0) \cdot \exp(\beta_1 x_1) \cdot \ldots \cdot \exp(\beta_k x_k)
\end{equation}
```


[^poiparam]: Der Poisson-Parameter wird von unterschiedlichen Autoren als $\lambda$ oder $\mu$ bezeichnet, und ich habe mich noch nicht für eine Variante entschieden).


Vgl. @fahrmeirRegressionModelleMethoden2009

Für das log-lineare Poisson-Modell entsprechen die resultierenden Koeffizienten der Veränderung der log-counts – durch Exponentiation lassen diese sich als *incidence rate ratios* (*IRR*) interpretieren.

### Annahmen

Primäre Annahme für Poisson-Modelle: *Equidispersion*, i.e. für den Parameter der Poissonverteilung gilt 


1. Die Abhängige / Zielvariable $Y$ muss eine Zählung sein, i.e. die Verteilung ist diskret mit einem einzelnen Parameter $\lambda$.
2. $y \in \mathbb{N}_0$, insbesondere: $Y$ muss 0 enthalten können (siehe auch \@ref(trunc-cens) [Truncation und Censoring](#trunc-cens))
3. Beobachtungen sind unabhängig, i.e. weder longitudinal noch gepoolt.
   - Möglicher Test durch Vergleich der Modell-SE und der SE adjustiert durch:
   - 1. Robuste sandwich-estimators
   - 2. Bootstrapped SEs
   - 3. SE skaliert mit der $\chi^2$-Dispersionsstatistik: $se \cdot \sqrt{\chi^2}$
   - Große Unterschiede implizieren korrelierte Daten
4. Balanced: Die Zellen sind in etwa so besetzt wie es aufgrund der Poissonverteilung erwartet wird.
5. Erwartungswert und Varianz sind identisch (*equidispersion*), i.e. ein größerer Erwartungswert impliziert auch eine größere Varianz.
6. Die $\chi^2$-Statistik hat einen Wert nahe 1, i.e. beobachtete und erwartete Varianzen der response sind gleich (Dispersionsindex)
   - Check auf overdispersion: Boundary likelihood ratio test

(Nach Tabelle in [@hilbeModelingCountData2014], braucht noch Deduplizierung)

Alternative Formulierung nach @winkelmannEconometricAnalysisCount2010 (p. 64):

1. $f(y\ |\ \lambda) = \frac{e^{-\lambda} \lambda^y}{y!} \quad \lambda > 0, y = 0, 1, 2, \ldots$.
2. $\lambda = \exp(\mathbf{x}' \boldsymbol{\beta})$.
3. Beobachtungspaare $(y_i, x_i)$ sind unabhängig verteilt.

### Offset

Ein Offset wird benötigt, um auf ungleiche Expositionsdauern oder -gebiete zu adjustieren. Dazu dient der Koeffizient $t$, der die Länge der Zeit unter Exposition angibt:

\begin{equation}
f(y, \mu) = \frac{\exp(mu) (t\mu)^y}{y!}
\end{equation}

Damit entspricht $t\mu$ der Inzidenzrate des Outcomes adjustiert auf e.g. die geographische Lage oder Expositionsdauer. Ohne Offset entspräche $t = 1$.
Für als Offset wird in der Regel $\log(t)$ verwendet, womit gelten:

\begin{align*}
\hat{\lambda} &= \exp{x \boldsymbol{\beta} + \log(t)} \\
\Leftrightarrow \exp(x \boldsymbol{\beta}) &= \frac{\hat{\mu}}{t} \\
\Leftrightarrow \hat{\mu} &= t \exp(x \boldsymbol{\beta})
\end{align*}


In `R`:

```{r mod_pois_offset, eval = FALSE}
data(fasttrakg, package = "COUNT")

glm(die ~ anterior + hcabg + factor(killip), data = fasttrakg, 
family = poisson(), offset = log(cases))
```


### Poisson Inverse Gaussian (PIG) {#mod-pig}

- Annahme: Overdispersion besser über *inverse Gaussian* Verteilung als Gamma-Verteilung (siehe NBIN) beschreibbar

- Dispersionsparameter $\alpha$, Interpretation analog NBIN
- Interpretation der exponentierten Koeffizienten: IRRs

- Software:
- R: `gamlss` (CRAN)
- Stata: `pigreg` ()

### Generalized Poisson {#mod-gp}

- Auch mit dispersion/scale Parameter $\alpha$
- Analog NB: $\alpha = 0 \Rightarrow y \sim \mathrm{Pois}(\lambda)$
- Selling feature: $\alpha < 0$ ist möglich, im Gegensatz zu NB
- -> Underdispersion modellierbar

- Software: 
- [Vgl. Stackexchange Kommentar von Joseph Hilbe](https://stats.stackexchange.com/a/237177/80056)
- R: [`VGAM`](https://rdrr.io/cran/VGAM/man/genpoisson.html)



### Conway-Maxwell Poisson {#mod-comp}

- Software:
   - `CompGLM::glm.comp`
   - `COMPoissonReg` (GitHub: `lotze/COMPoissonReg`)
   - `compoisson` (Not sure if modelling)

## Negative Binomial (NB) {#mod-nb}

```{definition, name = "Negative Binomialverteilung"}
Nach @perumean-chaneyZeroinflatedOverdispersedWhat2013 (p. 1675):

Für $Y \sim NB(\mu, \theta)$ gilt
  
\begin{equation}
P(Y = y) = \frac{\Gamma(\theta + y)}{\Gamma(\theta) \Gamma(y+1)} \frac{\theta^\theta \mu^y}{(\theta + \mu)^{(\theta + y)}}, \quad y = 0, 1, 2, \ldots
\end{equation}

Mit $\mathbb{E}(Y) = \mu$ und $\mathrm{Var}(Y) = \mu + \frac{\mu^2}{\theta}$
```


- Derivation: Poisson-Gamma Mischmodell
- Erweiterung der Poissonverteilung um einen Dispersionsparameter $\alpha$
  - Wenn $\alpha > 0$: overdispersion
  - Wenn $\alpha = 0$: Äquivalent zu Poisson
- Interpretation der exponentierten Koeffizienten: IRRs
- Zwei Varianten: NB1, NB2
- Software Pitfalls:
  - Dispersionsparameter in R's `glm` bzw. `MASS::glm.nb` invertiert: $\theta = \frac 1 \alpha$
  - -> Äquivalenz zu Poisson bei $\theta \to \infty$
  
> "The negative binimial model adjusts for Poisson overdispersion; it **cannot be used to model underdispersed** Poisson data" 
> [@hilbeModelingCountData2014, p. 11]
  
  
Vgl @hilbeModelingCountData2014

### Heterogenous Negative Binomial (NBH) {#mod-nbh}

- Selling feature: Erlaubt Parametrisierung von $\alpha$
- -> Ursache für under-/overdispersion modellierbar

### Negative binomial-P (NB-P) {#mod-nbp}

- NB: Varianz statisch für alle Beobachtungen
- -> NB-P: Varianz kann für Beobachtungen variieren (Parameter $\rho$)

- Primärer Anwendungsfall: Bestimmen, ob NB1 oder NB2 besser passt
  - Wenn $\rho \approx 2$ -> NB2, sonst NB1 (@hilbeModelingCountData2014, p. 21)



## Zero-Inflated Models (*mixture models*) {#mod-zi}

- Logit/Probit Komponente für zeros
   - Unterschied: Modelliert Nullen im Gegensatz zu Einsen
- Binary zeros und count zeros werden durch beide Komponenten modelliert 
   - -> Nicht getrennt interpretierbar
- -> Erzeugen eigene PDF, e.g. ZIP, die mixture aus beiden Komponenten darstellt

Beispiel: Poisson-logit hurdle Modell, bestehend aus logit-Modell für zeros und zero-truncated Poisson für die non-zero counts

ZIP und ZINB wurde hergeleitet als zweiteilige mixture distributions. Die allgemeine Form für mixture distributions ist

\begin{equation}
P(Y = y) = p \cdot g_1(y) + (1-p) \cdot g_2(y)
\end{equation}

mit $p$ als *mixture proportion* und $g_1, g_2$ als Dichte-/Massefunktionen der beiden Komponenten.

In dieser Darstellung entspricht $p$ der *rate of zero-inflation* $\pi$, $g_1$ einer degenerierten 0-verteilung und $g_2$ einer Poisson-PMF.

```{definition, name = "Zero-Inflated Poisson Verteilung"}
Nach @perumean-chaneyZeroinflatedOverdispersedWhat2013 (p. 1675)

\begin{align}
P(Y = 0) &= \pi + (1-\pi) \cdot e^{-\mu} \\
P(Y = 1) &= (1 - \pi) \cdot \frac{\mu^y e^{-\mu}}{y!}
\end{align}
```

```{definition, name = "Zero-Inflated Negative Binomialverteilung"}
Nach @perumean-chaneyZeroinflatedOverdispersedWhat2013 (p. 1675)

\begin{align}
P(Y = 0) &= \pi + (1 - \pi) \cdot \frac{\theta^\theta}{(\theta + \mu)^\theta}  \\
P(Y = 1) &= (1 - \pi) \cdot \frac{\Gamma(\theta+y)}{\Gamma(\theta) \Gamma(y + 1)} \frac{\theta^\theta \mu^y}{(\theta + \mu)^{(\theta + y)}}
\end{align}
```

## Hurdle models {#mod-hurdle}

- *Nested* hurdle models: Beide Komponenten nested (e.g. beide Poisson).
- *Non-nested* hurdle models: Hurdle-Komponente als vollständig anderer Prozess betrachtet und via e.g. logit modelliert.

in zwei Komponenten:

1. Binary 0,1 response, (logit oder probit)
   - Modellierung der Wahrscheinlichkeit für die non-zero counts
2. Zero-truncated count model


- Erlauben sowohl under- als auch overdispersion
- Erlauben systematischen Unterschied im Prozess, der zu e.g. Outcomes = 0 vs. Outcomes > 0 führt

Offene Fragen: Interpretierbarkeit der binary Komponente?

```{definition, name = "Hurdle Model"}
Nach @winkelmannEconometricAnalysisCount2010, p. 179f:
  
Sei $g_1(0)$ die Wahrscheinlichkeit des Outcomes $0$ und $g_1(k), k = 1, 2, 3, \ldots$ die Wahrscheinlichkeitsfunktion für natürliche Zahlen, dann ist die Wahrscheinlichkeitsfunktion eines *hurdle-at-zero* Modells:
  
\begin{align*}
f(y = 0) &= g_1(0) \\
f(y = k) &= (1 - g_1(0)) g_2(k), \quad k = 1, 2, 3, \ldots
\end{align*}

Bzw. nach Mullahey (1986) mit $f_1$ und $f_2$ als PMFs für natürliche Zahlen

\begin{align*}
f(y = 0) &= f_1(0) \\
f(y = 1) &= \frac{1 - f_1(0)}{1 - f_2(0)} f_2(k) \\
         &= \Theta f_2(k), \quad k = 1, 2, 3, \ldots 
\end{align*}

Wobei 

- $f_2$ als *parent process* bezeichnet wird
- $1 - f_1(0)$ die Wahrscheinlichkeit angibt, die Hürde ($y = 0$) zu "überqueren" (*"crossing the hurdle"*).
- $1 - f_2(0)$ zur Normalisierung von $f_2$ dient, um deren truncation zu berücksichtigen.

Der Erwartungswert des hurdle models ist

$$
  \mathbb{E}_h(y) = \Theta \sum_{k=1}^\infty k f_2(k) = \Theta \mathbb{E}_2(y)
$$
  
Mit $\mathbb{E}_2$ als Erwartunsgwert von $f_2$.

Mit $f_2 = \mathrm{Poisson}$:
  
- $0 < \Theta < 1$: Overdispersion  
- $1 < \Theta < \frac{\lambda_2 + 1}{\lambda_2}$: Underdispersion

```


> "By far the most popular hurdle model in practice is the hurdle-at-zero negative bonomial model"
[@winkelmannEconometricAnalysisCount2010, p. 183]

mit $f_1 \sim NB(\beta_1, \alpha_1)$ und $f_2 \sim NB(\beta_2, \alpha_2)$
