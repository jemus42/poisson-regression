---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Modelle {#modelle}

Ein Überblick einiger Modelle mit parametrisierter Varianz (nach @hilbeModelingCountData2014, p. 12).

```{r models_table_1, echo=FALSE}
tibble::tribble(
  ~Model,                         ~Mean,  ~Variance,
  "Poisson",                     "$\\mu$", "$\\mu$",
  "Negative Binomial (NB1)",     "$\\mu$", "$\\mu (1 + \\alpha) = \\mu + \\alpha\\mu$",
  "Negative Binomial (NB2)",     "$\\mu$", "$\\mu (1 + \\alpha\\mu) = \\mu + \\alpha\\mu^2$",
  "Poisson Inverse Gaussian (PIG)", "$\\mu$", "$\\mu (1 + \\alpha\\mu^2) = \\mu + \\alpha\\mu^3$",
  "Negative binomial-P (NBP)",   "$\\mu$", "$\\mu (1 + \\alpha\\mu^p) = \\mu + \\alpha\\mu^p$",
  "Generalized Poisson (GP)",    "$\\mu$", "$\\mu (1 + \\alpha\\mu)^2 = \\mu + 2\\alpha\\mu^3 + \\alpha^2\\mu^3$"
 ) %>%
  kable(booktabs = TRUE, escape = FALSE, linesep = "") %>%
  kable_styling(position = "center", protect_latex = TRUE)
```

## Zweiparametrische Modelle

### Negativ Binomial (NB) {#mod-nb}

Die Negative Binomialverteilung (*NB*) kann als zweiparametrische Erweiterung der *Poisson* betrachtet werden, wobei die Varianz (separat vom Erwartungswert) als Gamma-verteilte Zufallsvariable betrachtet wird [^Unter Umständen kann von einem *Poisson-Gamma Mischmodell* die Rede sein – damit ist genau dieser Umstand gemeint]. 

```{definition, name = "Negative Binomialverteilung"}
Nach @perumean-chaneyZeroinflatedOverdispersedWhat2013 (p. 1675):

Für $Y \sim NB(\mu, \theta)$ gilt
  
\begin{equation}
P(Y = y) = \frac{\Gamma(\theta + y)}{\Gamma(\theta) \Gamma(y+1)} \frac{\theta^\theta \mu^y}{(\theta + \mu)^{(\theta + y)}}, \quad y = 0, 1, 2, \ldots
\end{equation}

Mit $\mathbb{E}(Y) = \mu$ und $\mathrm{Var}(Y) = \mu + \frac{\mu^2}{\theta}$
  
```


Der gängigste Anwendungsfall der *NB* findet sich bei Daten mit nicht korrigierbarer overdispersion (siehe Abschnitt \@ref(overdispersion)), da der Parameter $\theta$ (oder auch $\alpha = \frac 1 \theta$) als *Dispersionsparameter* dient. Für diesen Parameter gilt:


```{definition nbdisppar, name = "NB-Dispersionsparameter"}

Im Allgemeinen wird der Parameter $\theta$ verwendet mit der Interpretation (relativ zum Poisson-Modell):

\begin{align}
  \theta &> 0 &&\Longrightarrow \text{ Overdispersion} \\
  \theta &\to \infty &&\Longrightarrow \text{ Äquivalent zur Poissonverteilung}
\end{align}

Unter anderem in R (z.B. `MASS::glm.nb`) wird die inverse Variante $\alpha = \frac 1 \theta$ verwendet, womit gilt:

$$\mathrm{Var}(Y) = \mu + \alpha \mu^2$$
  
  
\begin{align}
  \alpha &= 0 &&\Longrightarrow \text{ Äquivalent zur Poissonverteilung} \\
  \alpha &> 0 &&\Longrightarrow \text{ Overdispersion}
\end{align}

```

(Vgl. @hilbeModelingCountData2014, @hilbe2011NegativeBinomial)


Der wohl wichtigste Aspekt des Dispersionsparameters, unabhängig davon ob $\alpha$ oder $\theta$ verwendet wird, ist sein Vorzeichen: Er ist _immer_ positiv, das heißt die Varianz der NB ist entweder _größer oder gleich_ der Poisson, oder mit anderen Worten:

> "The negative binomial model adjusts for Poisson overdispersion; it **cannot be used to model underdispersed** Poisson data" 
>
> --- [@hilbeModelingCountData2014 (p. 11), eigene Hervorhebung]



- Interpretation der exponentierten Koeffizienten: IRRs
- Zwei Varianten: NB1, NB2

  

### Poisson Inverse Gaussian (PIG) {#mod-pig}

So wie die *NB* als mixture aus Poisson-Verteilung mit Gamma-verteilter Varianz betrachtet werden kann, ist die *Poisson Inverse Gaussian* (*PIG*) eine mixture aus Poisson-Verteilung mit [invers-normalverteilter](https://en.wikipedia.org/wiki/Inverse_Gaussian_distribution) Varianz. Demnach kann man *PIG* als Alternative zur *NB* verwenden.


- Dispersionsparameter $\alpha$, Interpretation analog NBIN
- Interpretation der exponentierten Koeffizienten: IRRs

- Software:
- R: `gamlss` (CRAN)
- Stata: `pigreg`

### Generalized Poisson {#mod-gp}

- Auch mit dispersion/scale Parameter $\alpha$
- Analog NB: $\alpha = 0 \Rightarrow y \sim \mathrm{Pois}(\lambda)$
- Selling feature: $\alpha < 0$ ist möglich, im Gegensatz zu NB
- -> Underdispersion modellierbar

- Software: 
- [Vgl. Stackexchange Kommentar von Joseph Hilbe](https://stats.stackexchange.com/a/237177/80056)
- R: [`VGAM`](https://rdrr.io/cran/VGAM/man/genpoisson.html)


### Heterogenous Negative Binomial (NBH) {#mod-nbh}

- Selling feature: Erlaubt Parametrisierung von $\alpha$
- -> Ursache für under-/overdispersion modellierbar

### Negative binomial-P (NB-P) {#mod-nbp}

- NB: Varianz statisch für alle Beobachtungen
- -> NB-P: Varianz kann für Beobachtungen variieren (Parameter $\rho$)

- Primärer Anwendungsfall: Bestimmen, ob NB1 oder NB2 besser passt
  - Wenn $\rho \approx 2$ -> NB2, sonst NB1 (@hilbeModelingCountData2014, p. 21)


## Dreiparametrische Modelle


### Conway-Maxwell Poisson {#mod-comp}

```{definition, name = "Conway-Maxwell-Poisson Modell (CMP)"}
Nach @shmueli2005UsefulDistribution (p. 129):
  
\begin{align}
P(X = x) &= \frac{\lambda^x}{(x!)^\nu} \frac{1}{Z(\lambda, \nu)}, \quad x = 0, 1, 2, \ldots \\
Z(\lambda, \nu) &= \sum_{j = 0}^\infty \frac{\lambda^j}{(j!)^\nu} \\
\\
\lambda > 0&, \nu \ge 0
\end{align}

Mit nichtlinearer Zerfallsrate $\nu$ *rate of decay*, so dass:

\begin{equation}  
\frac{P(X = x -1)}{P(X = x)} = \frac{x^\nu}{\lambda}
\end{equation}
```

Die Verteilung hat als Spezialfälle:

- $\nu = 1 \Longrightarrow Z(\lambda, \nu) = exp(\lambda)$: Poisson
- $\nu \to \infty \Longrightarrow Z(\lambda, \nu) \to 1 + \lambda$: Bernoulli mit $P(X = 1) = \frac{\lambda}{1+\lambda}$
- $\nu = 0,\ \lambda < 1$: Geometrisch mit $P(X = x) = \lambda^x (1 - \lambda)$


- **Vorteile**:
- "Low cost", i.e. "nur" ein zusätzlicher Parameter
- Einfach zu handhaben
- Over- und underdispersion abbildbar
- Zero-inflation abbildbar

- Software:
   - `CompGLM::glm.comp`
   - `COMPoissonReg` (GitHub: `lotze/COMPoissonReg`)
   - `compoisson` (Not sure if modelling)

## Zero-Inflated Models (*mixture models*) {#mod-zi}

- Logit/Probit Komponente für zeros
   - Unterschied: Modelliert Nullen im Gegensatz zu Einsen
- Binary zeros und count zeros werden durch beide Komponenten modelliert 
   - -> Nicht getrennt interpretierbar
- -> Erzeugen eigene PDF, e.g. ZIP, die mixture aus beiden Komponenten darstellt

Beispiel: Poisson-logit hurdle Modell, bestehend aus logit-Modell für zeros und zero-truncated Poisson für die non-zero counts

ZIP und ZINB wurde hergeleitet als zweiteilige mixture distributions. Die allgemeine Form für mixture distributions ist

\begin{equation}
  P(Y = y) = p \cdot g_1(y) + (1-p) \cdot g_2(y)
\end{equation}

mit $p$ als *mixture proportion* und $g_1, g_2$ als Dichte-/Massefunktionen der beiden Komponenten.

In dieser Darstellung entspricht $p$ der *rate of zero-inflation* $\pi$, $g_1$ einer degenerierten 0-verteilung und $g_2$ einer Poisson-PMF.

```{definition, name = "Zero-Inflated Poisson Verteilung (ZIP)"}
Nach @perumean-chaneyZeroinflatedOverdispersedWhat2013 (p. 1675)

\begin{align}
P(Y = 0) &= \pi + (1-\pi) \cdot e^{-\mu} \\
P(Y = 1) &= (1 - \pi) \cdot \frac{\mu^y e^{-\mu}}{y!}
\end{align}
```

```{definition, name = "Zero-Inflated Negative Binomialverteilung (ZINB)"}
Nach @perumean-chaneyZeroinflatedOverdispersedWhat2013 (p. 1675)

\begin{align}
P(Y = 0) &= \pi + (1 - \pi) \cdot \frac{\theta^\theta}{(\theta + \mu)^\theta}  \\
P(Y = 1) &= (1 - \pi) \cdot \frac{\Gamma(\theta+y)}{\Gamma(\theta) \Gamma(y + 1)} \frac{\theta^\theta \mu^y}{(\theta + \mu)^{(\theta + y)}}
\end{align}
```

