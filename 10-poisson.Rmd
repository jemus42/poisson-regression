---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Das Poisson-Modell {#poisson-modell}

Das Poisson-Modell ist die allgemeine Grundlage für die Modellierung von Zählvorgängen / Counts, und auch wenn es in seiner "reinen" Form in der Praxis meist nicht ausreicht, bauen alle weiteren Methoden auf die eine oder andere Art darauf auf. Auch die häufig verwendete Negative Binomialverteilung ist letztlich eine Poisson-Verteilung mit Gamma-verteilter Varianz, also eine Erweiterung der Poisson um einen zusätzlichen Parameter. Das gleiche Prinzip findet sich in allen hier besprochenen Verteilungen. 

Für eine ausführliche Diskussion der Eigenschaften, siehe @winkelmannEconometricAnalysisCount2010 (p. 7-20).

Grundlage zur Modellierung ist das GLM mit den dazugehörigen Voraussetzungen:

- Die abhängige Variable $Y$ kommt aus der Exponentialfamilie (Normal-, Poisson-, Gamma-, Binomialverteilung)
- Modelliert wird der lineare Prädiktor $\eta_i = \boldsymbol{x}_i' \boldsymbol{\beta}$.
- Response- und Linkfunktionen $h(x)$ und $g(x) = h^{-1}(x)$ 


```{definition, name = "Poisson-Verteilung"}
Eine Poisson-verteilte Zufallsvariable $Y \sim \mathrm{Poi}(\mu)$ [^poiparam] hat die Dichte

\begin{equation*}
\mathrm{P}(Y = y) = \frac{\mu^y \exp(-\mu)}{y!} \quad, y \in \mathbb{N}_0
\end{equation*}
```

```{r poissondists, echo=FALSE, fig.cap="Poisson-Verteilungen mit ausgewählten Parametern."}
map_df(c(0.5, 1, 2, 5, 10, 15), ~{
  tibble(
    mu = .x,
    x = 0:20,
    poi = dpois(x, mu)
  )
}) %>%
  ggplot(aes(x = x, y = poi, color = factor(mu), fill = factor(mu))) +
  geom_path(aes(group = mu), linetype = "dotted") +
  geom_point(shape = 21, color = "black", size = 2.5, stroke = .2) +
  #geom_segment(aes(x = x, xend = x, y = 0 , yend = poi)) +
  scale_color_viridis_d(direction = -1, guide = FALSE) +
  scale_fill_viridis_d(
    direction = -1, guide = guide_legend(
      keywidth = .5,
      nrow = 1,
      direction = "horizontal"
      )
  ) +
  labs(
    title = "Poi(\u00b5)",
    x = "y", y = "Poi(y, \u00b5)", fill = "\u00b5"
  ) +
  theme(legend.position = c(.7, 1))
```

```{definition poisson-modell, name = "Poisson-Modell"}
Die Zielvariablen $y_i \in \mathbb{N}_0$ sind (bedingt) unabhängig gegeben der Kovariablen $x_{i1}, x_{i2}, \ldots, x_{ik}$.

Die Rate $\mu_i = \mathbb{E}(y_i\ |\ \mathbf{x}_i)$ der Poissonverteilung wird in der Regel log-linear modelliert als

\begin{align*}
  \log(\mu_i) &= \eta_i 
    = \mathbf{x}_i^\prime \boldsymbol{\beta} 
    = \beta_0 + \beta_1 x_1 + \ldots + \beta_k x_{ik} \\
  \mu_i &= \exp(\eta_i) 
    = \exp(\beta_0) \cdot \exp(\beta_1 x_1) \cdot \ldots \cdot \exp(\beta_k x_k)
\end{align*}

```


[^poiparam]: Der Poisson-Parameter wird von unterschiedlichen Autoren als $\lambda$ oder $\mu$ bezeichnet, und ich habe mich noch nicht für eine Variante entschieden).


Vgl. @fahrmeirRegressionModelleMethoden2009

Für das log-lineare Poisson-Modell entsprechen die resultierenden Koeffizienten der Veränderung der log-counts – durch Exponentiation lassen diese sich als *incidence rate ratios* (*IRR*) interpretieren.

Um auf ungleiche Expositionsdauern oder -gebiete zu adjustieren wird ein **offset** (oder auch *exposure*) benötigt. Dazu dient der Koeffizient $t$, der die Länge der Zeit unter Exposition angibt:

\begin{equation}
f(y, \mu) = \frac{\exp(\mu) (t \mu)^y}{y!}
\end{equation}

Damit entspricht $t \mu$ der Inzidenzrate des Outcomes adjustiert auf e.g. die geographische Lage oder Expositionsdauer. Ohne Offset entspräche $t = 1$.
Für als Offset wird in der Regel $\log(t)$ verwendet, womit gelten:

\begin{align*}
\hat{\mu} &= \exp{x \boldsymbol{\beta} + \log(t)} \\
\Leftrightarrow \exp(x \boldsymbol{\beta}) &= \frac{\hat{\mu}}{t} \\
\Leftrightarrow \hat{\mu} &= t \exp(x \boldsymbol{\beta})
\end{align*}

Ein offset kann z.B. in `R` via `+ offset(log(variable))` in der model `formula` oder über das Argument `offset = log(variable)` in `glm` und verwandten Funktionen angegeben werden.


## Annahmen

1. Die Abhängige / Zielvariable $Y$ muss eine Zählung sein, i.e. die Verteilung ist diskret mit einem einzelnen Parameter $\mu$ der Poisson-Verteilung für Erwartungswert und Varianz.
2. $y \in \mathbb{N}_0$, insbesondere: $Y$ muss 0 enthalten *können* (siehe auch \@ref(trunc-cens) [Truncation und Censoring](#trunc-cens))
3. Beobachtungen sind *unabhängig*, i.e. weder longitudinal noch gepoolt.
   - Möglicher Test durch Vergleich der Modell-SE und der SE adjustiert durch robuste sandwich-estimators (siehe \@ref(sandwich)): Große Unterschiede implizieren korrelierte Daten
4. Balanced: Die Zellen sind in etwa so besetzt wie es aufgrund der Poissonverteilung erwartet wird.
5. Erwartungswert und Varianz sind identisch (*equidispersion*), i.e. ein größerer Erwartungswert impliziert auch eine größere Varianz (siehe \@ref(dispersion)).
6. Die $\chi^2$-Statistik hat einen Wert nahe 1, i.e. beobachtete und erwartete Varianzen der response sind gleich (Dispersionsindex).

(Nach Tabelle in [@hilbeModelingCountData2014])

Alternative Formulierung nach @winkelmannEconometricAnalysisCount2010 (p. 64):

1. $f(y\ |\ \mu) = \frac{e^{-\mu} \mu^y}{y!} \quad \mu > 0, y = 0, 1, 2, \ldots$.
2. $\mu = \exp(\mathbf{x}' \boldsymbol{\beta})$.
3. Beobachtungspaare $(y_i, x_i)$ sind unabhängig verteilt.

## Dispersion {#dispersion}

```{definition def-dispersions, name = "Equi-, Extra-, Over-, Underdispersion"}
Für Zählvariablen $y_i \in \mathbb{N}_0$ und erklärenden Variablen $\mathbf{x}_i$ gilt innerhalb eines Modells:

\begin{align*}
\text{Equdispersion:}  \quad & \mathrm{Var}(y_i) = \mathrm{Var}(y_i\ |\ \mathbf{x}_i) \\
\text{Extradispersion:}\quad & \mathrm{Var}(y_i) \neq \mathrm{Var}(y_i\ |\ \mathbf{x}_i) \\
\text{Overdispersion:} \quad & \mathrm{Var}(y_i) > \mathrm{Var}(y_i\ |\ \mathbf{x}_i) \\
\text{Underdispersion:}\quad & \mathrm{Var}(y_i) < \mathrm{Var}(y_i\ |\ \mathbf{x}_i)
\end{align*}

```


```{definition def-pois-overdispersion, name = "Poisson-Overdispersion"}
Innerhalb eines Poisson-Modells (vgl. Abschnitt \@ref(poisson-modell)) mit der Annahme

\begin{align*}
y_i\ |\ \mathbf{x}_i &\sim \mathrm{Poi}(\mu_i) \\[1.5em]
\mu &= \mathbb{E}(y_i\ |\ \mathbf{x}_i) = \mathrm{Var}(y_i\ |\ \mathbf{x}_i) \quad \text{(Equidispersion)}
\end{align*}

spricht man von **Poisson-Overdispersion** wenn die Varianz der Beobachtungen die erwartete Varianz des Poisson-Modells übersteigt:

\begin{equation*}
  \mathrm{Var}(y_i\ |\ \mathbf{x}_i) > \mathbb{E}(y_i\ |\ \mathbf{x}_i)
\end{equation*}

in einem Modell mit overdispersion gilt die Annahme:

\begin{equation*}
  \mathrm{Var}(y_i\ |\ \mathbf{x}_i) = \theta \cdot \mu_i
\end{equation*}

Mit *Dispersionsparameter* $\theta$ [vgl. @fahrmeirRegressionModelleMethoden2009, p. 210]

```


Als Dispersionsstatistik können *deviance dispersion* oder *Pearson dispersion* berechnet werden. Laut @hilbeModelingCountData2014 ist die *Pearson dispersion* zu bevorzugen, da sie für echte Poisson-Modelle gleich 1 ist, wohingegen die *deviance dispersion* nach oben verzerrt ist.


```{definition def-pearsondisp, name = "Pearson-Dispersion"}
Nach @hilbeModelingCountData2014 (p. 77ff):

Die Pearson $\chi^2$-Statistik ist die Summe der quadrierten (Pearson-)Residuen gewichtet mit der Modellvarianz:

\begin{equation*}
\chi_{\text{Pearson}}^2 = \sum_{i=1}^n \frac{(y_i - \hat{\mu}_i)^2}{\mathrm{Var}(\hat{\mu}_i)}
\end{equation*}

und die **Pearson-Dispersionsstatistik**:
  
\begin{equation*}
D = \frac{\chi_{\text{Pearson}}^2}{\mathrm{df}}
\end{equation*}

Mit der Interpretation

\begin{equation*}
\mathrm{D} =
  \begin{cases}
    < 1 & \Longrightarrow \text{Underdispersion} \\
      1 & \Longrightarrow \text{Equidispersion (Poisson)} \\
    > 1 & \Longrightarrow \text{Overdispersion}
  \end{cases}
\end{equation*}

Für Modelle moderater Größe kann man ab Werten über 1.25 von overdispersion sprechen, wobei für große Stichproben auch schon ab 1.05 overdispersion vorliegen kann – zumindest nach @hilbeModelingCountData2014 (p. 82), der aber leider keine konkreten Angaben für seine Definition von "moderaten" oder "großen" Stichproben macht.

```

In `R` kann die Pearson-Dispersion wie folgt berechnet werden:

```r
# Model fit
mod <- glm(y ~ x1 + x2 + x3, data = sim, family = poisson(link = "log"))

# Pearson dispersion
sum(resid(mod, type = "pearson")^2) / mod$df.residual
```

...wofür wir in Abschnitt \@ref(helperfuns) eine Hilfsfunktion `dispersion()` definiert haben.

### Overdispersion {#overdispersion}

Der vermutlich häufigste Fall für Count-Daten: Die Varianz der abhängigen Variable ist größer als ihr Erwartungswert, bzw. größer als ihre erwartete Varianz innerhalb eines Modells. 
@hilbeModelingCountData2014 unterscheidet zwischen echter und scheinbarer (*apparent*) Overdispersion, wobei letztere oft durch geeignete Korrekturen kompensiert werden kann, wobei *echte* Overdisperion sowohl Parameterschätzung als auch Modellanpassung im Allgemeinen beeinträchtigt.

Nach @hilbeModelingCountData2014 (p. 82) entsteht *echte* Overdispersion durch:

- Positive Korrelation zwischen responses
- Große Variation zwischen response-probabilities und counts
- Verletzungen der Verteilungsannahme (i.e. Poissonverteilung)
- "Proneness": Frühere Ereignisse beeinflussen das Auftreten späterer Ereignisse [^poiind]

[^poiind]: Diese Annahme (Unabhängigkeit der Ereignisse) der Poissonverteilung ist auch der Grund, warum sich die Poissonverteilung prinzipiell **nicht** eignet um Epidemien wie Ebola zu modellieren. Freundliche Grüße an Frau Pigeot, "Statistische Modellierung I", WiSe 18/19.


Ursachen für *scheinbare* (*apparent*), und damit (bedingt) korrigierbare Overdispersion nach @hilbeModelingCountData2014 (p. 41, 82):

1. Fehlende explanatorische Prädiktoren
2. Ausreißer
3. Fehlende Interaktionsterme
4. Ein Prädiktor muss transformiert werden
5. Die Daten sind zu dünn besetzt (*sparse*)
6. Fehlende Werte, die nicht zufällig sind (missing not at random, *MNAR* – siehe auch Anhang \@ref(appendix-missingness)

Ein einfaches simuliertes Beispiel zur Auswirkung von fehlenden Prädiktoren:

```{r overdisp_misspecified_model_sim}
# Generate binary variable in [0, 1] with a given proportion of 1's
rbinary <- function(n, prob = 0.5) {
  sample(0:1, size = n, replace = TRUE, prob = c(1 - prob, prob))
}

set.seed(436)
n <- 1000

sim <- tibble(
  x1 = rbinary(n, .1),
  x2 = rbinary(n, .2),
  x3 = rbinary(n, .3),
  eta = 0.5 + 1 * x1 + 2 * x2 + 0.5 * x3,
  mu = exp(eta),
  py = rpois(n, mu)
)

# Korrektes modell:
mod <- glm(py ~ x1 + x2 + x3, data = sim, family = poisson(link = "log"))
dispersion(mod)

# Modell mit fehlendem Prädiktor:
mod2 <- glm(py ~ x1 + x3, data = sim, family = poisson(link = "log"))
dispersion(mod2)
```

### Underdispersion

Underdispersion ist der Fall, wenn vorliegende Daten eine geringere Varianz aufweisen, als auf Basis eines Poisson-Modells erwartet würde, das heißt die Daten sind "enger zusammengeklumpt".
Bei underdispersion werden die Standardfehler des Modells *über*schätzt, im Gegensatz zur overdispersion, bei der Standardfehler *unter*schätzt werden [@hilbeModelingCountData2014, p. 210].

Im Allgemeinen wird für diese Situation die [generalized Poisson empfohlen](https://stats.stackexchange.com/a/237177/80056)  [@hilbeModelingCountData2014], da diese Erweiterung der Poisson-Verteilung nicht nur einen zusätzlichen Parameter für die Varianz hat (analog NB, PIG), sondern dieser Parameter auch negativ sein kann.

Weiterhin taucht im Kontext von hurdle models (siehe \@ref(mod-hurdle)) folgende Bemerkung auf:

> [...] that underdispersion occurs if **zeros are less frequent than the parent distribution would predict**.
> The higher the expected value of the Poisson distribution, the lower the predicted probability of zero outcome and the lower the scope for underdispersion.
> -- [@winkelmannEconometricAnalysisCount2010, p. 180 (eigene Hervorhebung)]
