---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Annahmen und Einschränkungen

Es gelten Standardannahmen des GLM:

- $Y$ kommt aus der Exponentialfamilie (Normal-, Poisson-, Gamma-, Binomialverteilung)
- $\eta_i = \boldsymbol{x}_i' \boldsymbol{\beta}$ als linearer Operator
- Response- und Linkfunktionen $h(x)$ und $g(x) = h^{-1}(x)$

## Dispersion {#dispersion}

```{definition, name = "Dispersions"}
\begin{align*}
\text{Equdispersion: }  \quad & \lambda_i = \mathbb{E}(y_i) = \mathrm{Var}(y_i) 
                        \quad  \mathrm{Var}(y_i) = \mathrm{Var}(y_i\ |\ \mathbf{x}_i) \\
\text{Extradispersion: }\quad & \mathrm{Var}(y_i) \neq \mathrm{Var}(y_i\ |\ \mathbf{x}_i) \\
\text{Overdispersion: } \quad & \mathrm{Var}(y_i) > \mathrm{Var}(y_i\ |\ \mathbf{x}_i) \\
\text{Underdispersion: }\quad & \mathrm{Var}(y_i) < \mathrm{Var}(y_i\ |\ \mathbf{x}_i)
\end{align*}

Insbesondere "Poisson-Ovderdispersion":
  
$$\mathrm{Var}(y_i) > \mathbb{E}(y_i)$$

In einem Modell mit Extradispersion gilt die Annahme:

\begin{equation}
\mathrm{Var}(y_i\ |\ \mathbf{x}_i) = \theta \cdot \lambda_i
\end{equation}

Mit *Dispersionsparameter* $\theta$ [vgl. @fahrmeirRegressionModelleMethoden2009, p. 210]

```

Zur expliziten Modellierung des Despersionparameters kann ein NBH Modell (\@ref(mod-nbh)) genutzt werden.

Als Dispersionsstatistik kann die Deviance (*deviance dispersion*) oder oder *pearson dispersion* berechnet werden. Laut @hilbeModelingCountData2014 ist die *Pearson dispersion* zu bevorzugen, da sie für echte Poisson-Modelle gleich 1 ist, wohingegen die *deviance dispersion* nach oben verzerrt ist.


```{definition, name = "Pearson Dispersion"}
Sei $\chi_{\text{Pearson}}^2$ die Pearson-Dispersionsstatistik eines GLMs und $df$ die dazugehörigen residualen Freiheitsgrade, dann ist die **Pearson-Dispersionsstatistik**:

\begin{align}
\frac{\chi_{\text{Pearson}}^2}{df}
\end{align}

Mit der Interpretation

\begin{equation*}
\frac{\chi_{\text{Pearson}}^2}{df} =
\begin{cases}
< 1 & \Longrightarrow \text{Underdispersion} \\
1 & \Longrightarrow \text{Equidispersion (Poisson korrekt)} \\
> 1 &\Longrightarrow \text{Overdispersion}
\end{cases}
\end{equation*}
```



In `R`:

```r
# Model fit
mod <- glm(y ~ x1 + x2 + x3, data = sim, family = poisson(link = "log"))

# Pearson dispersion
sum(resid(mod, type = "pearson")^2) / mod$df.residual
```

Im Folgenden wird folgende Funktion verwendet:

```{r, pearson_disp_function}
dispersion <- function(model, type = "pearson") {
  sum(resid(model, type = type)^2) / model$df.residual
}
```



### Overdispersion

Der vermutlich häufigste Fall für Count-Daten. 

Kriterien für Overdispersion nach @hilbeModelingCountData2014, p. 41

1. Fehlende explanatorische Prädiktoren
2. Die Daten enthalten Ausreißer
3. Im Modell fehlen Interaktionsterme
4. Ein Prädiktor muss transformiert werden
5. Die Daten sind zu dünn besetzt (*sparse*) (?)
6. Fehlende Werte, die nicht zufällig sind (missing not at random, *MNAR*)

Gründe für overdispersion *kann* zero-inflation sein, allerdings bedeutet das nicht direkt, dass auch ein entsprechendes Modell (ZIP, ZINB...) verwendet werden muss – ggf. lässt sich die overdispersion bereits durch ein NB Modell "auffangen". 

#### Umgang mit Overdispersion {-}

##### Quasipoisson: Skalierung der Standardfehler {-}

$$se(\beta_k) \cdot \sqrt{\chi^2}$$
Wobei $\chi^2$ der Pearson-Dispersionsindex ist (vgl. @hilbeModelingCountData2014, p. 92ff)

In `R` passiert genau das, wenn in `family = quasipoisson()`.

Nachteil: Es wird zuerst ein reguläres Poisson-Modell gefittet, Standardfehler und Dispersionsindex bestimmt, und dann dasselbe Modell mit skalierten Standardfehlern erneut gefittet – dementsprechend ist diese Methode vermutlich für größere Datensätze eher ineffizient.


##### Robuste Varianzschätzer / Sandwich Estimators {-}

Können auch "per default" verwendet werden, da die resultierenden Schätzer im Falle tatsächlich unkorrellierter Daten äquivalent zu den Standardfehlern des Modells sind (i.e. "schadet nicht").

Bootstrapped SEs wiederum erfordern mehr Aufwand, ähneln aber den robusten SEs sowieso sehr stark.



### Underdispersion

Underdispersion entsteht, wenn die Daten eine geringere Varianz aufweisen, als auf Basis eines Poisson- oder NB-Modells erwartet würde.
Bei nichtberücksichtigter underdispersion werden die Standardfehler des Modells überschätzt [@hilbeModelingCountData2014, p. 210].

Im Kontext von hurdle models taucht folgende Bemerkung auf:

> [...] that underdispersion occurs if zeros are less frequent than the parent distribution would predict.
> The higher the expected value of the Poisson distribution, the lowert the predicted probability of zero outcome and the lower the scope for underdispersion.
> -- [@winkelmannEconometricAnalysisCount2010, p. 180]

Im Allgemeinen wird [generalized Poisson](https://stats.stackexchange.com/a/237177/80056) (R: [`VGAM`](https://rdrr.io/cran/VGAM/man/genpoisson.html)) empfohlen [@hilbeModelingCountData2014].


### Beispiel nach @hilbeModelingCountData2014, p. 211ff

Grundlage ist der Datensatz `azprocedure` (siehe Abschnitt \@ref(data)) zur Dauer des Krankenhausaufenthalts nach einer von zwei kardiovaskulären Operationen mit folgenden hier relevanten Variablen:

- `los`: Length of hospital stay
- `sex`: Male (1), female(0)
- `admit`: Type of admission. Urgent/emergency (1), elective (0)

Zuerst werfen wir einen Blick auf die Daten und fitten ein reguläres Poissonmodell.

```{r underdisp_azprocedure_over}
data(azprocedure, package = "COUNT")

# Mittelwert & Varianz von 'los'
tibble(
  n = nrow(azprocedure),
  mean = mean(azprocedure$los),
  var = var(azprocedure$los)
)

# Barchart: So grob poissonverteilt?
ggplot(data = azprocedure, aes(x = los)) +
  geom_bar(alpha = .75) +
  labs(
    title = "Hospital length of stay (LOS)",
    subtitle = "azprocedure data (Hilbe 2014)",
    x = "LOS", y = "Count" 
  )

# Model fit
model_azproc <- glm(los ~ procedure + sex + admit, 
                    data = azprocedure, family = poisson())

# Model output (ohne exponentierte Koeffizienten)
pander(model_azproc)

# Pearson Dispersion:
dispersion(model_azproc)
```

Der Dispersionsindex lässt auf overdispersion schließen.  
Betrachten wir ein Subset der Daten, indem wir nur Beobachtungen mit $\mathtt{LOS} \le 8$ betrachten, erhalten wir ein anderes Bild:

```{r underdisp_azprocedure_under}
azprocedure_subset <- subset(azprocedure, los <= 8)

# Mittelwert & Varianz von 'los'
tibble(
  n = nrow(azprocedure),
  mean = mean(azprocedure$los),
  var = var(azprocedure$los)
)

# Barchart
ggplot(data = azprocedure_subset, aes(x = los)) +
  geom_bar(alpha = .75) +
  labs(
    title = "Hospital length of stay (LOS)",
    subtitle = "Subset (LOS <= 8) der azprocedure data (Hilbe 2014)",
    x = "LOS", y = "Count" 
  )

model_azproc_u <- glm(los ~ procedure + sex + admit, 
                      data = azprocedure_subset, family = poisson())

pander(model_azproc_u)
dispersion(model_azproc_u)
```


## Zeros {#zeros}



### Zero Inflation

Problem: "Excess zeros", i.e. die gewählte Dichtefunktion sagt für $P(y_i = 0\ |\ x_i)$ eine deutlich kleinere Wahrscheinlichkeit vor, als in gegebenen Daten tatsächlich vorliegen.


#### Tests auf Zero-Inflation {-}

- Vuong Test (vgl. @perumean-chaneyZeroinflatedOverdispersedWhat2013)
   - Für non-nested models
   - E.g Poisson vs. ZIP
- (Hausman Test)


Für sowohl overdispersion als auch zero-inflation: Score-Tests (?) [@perumean-chaneyZeroinflatedOverdispersedWhat2013, p. 1674, siehe auch entsprechende citations]

> As noted by Yang et al., the univariate situation is recommended for asssessing zero inflation als covariates reduce the power to detect zero inflation
> --- @perumean-chaneyZeroinflatedOverdispersedWhat2013, p. 1674

#### Modellierung {-}

Modellierung via 

- two part hurdle (Siehe Abschnitt \@ref(mod-zi))
- mixture models (Siehe Abschnitt \@ref(mod-hurdle))

[@hilbeModelingCountData2014, p. 19]


Ob hurdle model oder zero-inflated model die bessere Wahl ist hängt mitunter davon ab, welche Annahmen über die _Ursache der Nullen_ getroffen werden können.  
Wenn es eine echte Trennung der Mechanismen (*"separation of mechanisms"*) gibt, die die Nullen und die positiven counts verursachen, dann wäre ein hurdle model eher angemessen.  
Wenn sich die Nullen überlappen, es also keine getrennten Prozesse zu geben scheint, dann wären zero-inflated models angemessen [@hilbeModelingCountData2014, p. 209].

Im Falle von binären Outcomes stellt sich die Frage, inwiefern es sinnvoll ist hurdle oder zeri-inflated models überhaupt anzuwenden, da abseits der expliziten Modellierung der Nullen vermutlich zu wenig Information für ein geeignetes count model verbleibt.



### Zero Truncation

Wenn die Beobachtungen keine Nullen enthalten bzw. im Modell nicht möglich sind, können *zero-truncated* (ZT) Modelle verwendet werden.

- Zero-truncated Poisson (ZTP)

## Truncation und Censoring {#trunc-cens}

- **Truncation**: Bestimmte counts *nicht möglich*
  - z.B. keine Counts < 5 möglich -> *left truncation* (*right truncation* analog)
  - Interval truncation: Nur counts in Intervall $[a, b]$
- **Censoring**: Bestimmte counts *nicht beobachtet*, aber möglich
