---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Annahmen und Einschränkungen

Es gelten Standardannahmen des GLM:

- $Y$ kommt aus der Exponentialfamilie (Normal-, Poisson-, Gamma-, Binomialverteilung)
- $\eta_i = \boldsymbol{x}_i' \boldsymbol{\beta}$ als linearer Operator
- Response- und Linkfunktionen $h(x)$ und $g(x) = h^{-1}(x)$

## Dispersion {#dispersion}

```{definition, name = "Dispersions"}
\begin{align*}
\text{Equdispersion: }  \quad & \lambda_i = \mathbb{E}(y_i) = \mathrm{Var}(y_i) 
                        \quad  \mathrm{Var}(y_i) = \mathrm{Var}(y_i\ |\ \mathbf{x}_i) \\
\text{Extradispersion: }\quad & \mathrm{Var}(y_i) \neq \mathrm{Var}(y_i\ |\ \mathbf{x}_i) \\
\text{Overdispersion: } \quad & \mathrm{Var}(y_i) > \mathrm{Var}(y_i\ |\ \mathbf{x}_i) \\
\text{Underdispersion: }\quad & \mathrm{Var}(y_i) < \mathrm{Var}(y_i\ |\ \mathbf{x}_i)
\end{align*}

Insbesondere "Poisson-Ovderdispersion":
  
$$\mathrm{Var}(y_i) > \mathbb{E}(y_i)$$

In einem Modell mit Extradispersion gilt die Annahme:

\begin{equation}
\mathrm{Var}(y_i\ |\ \mathbf{x}_i) = \theta \cdot \lambda_i
\end{equation}

Mit *Dispersionsparameter* $\theta$ [vgl. @fahrmeirRegressionModelleMethoden2009, p. 210]

```

Zur Evaluation des Despersionparameters kann ein NBH Modell (\@ref(mod-nbh)) genutzt werden, wobei der  Dispersionsparameter modelliert wird.


@perumean-chaneyZeroinflatedOverdispersedWhat2013 schlagen folgendes Vorgehen vor um Overdispersion und Zero-Inflation zu erkennen:

```{r perumean_chaney_decision_tree}
grViz(readLines("PerumeanChaney.dot"))
```

Wobei im ersten Schritt sowohl Poisson als auch NB-Modelle gefittet werden, und dann nach Goodness-of-Fit (via LRT) (NB > Poisson?) entschieden wird.  
Im zweiten Schritt werden die jeweiligen Modelle (entweder Poisson oder NB) mit ihren ZI-Counterparts verglichen (model fit, Vuong-Test), analog Schritt 1.  
"LRT-Vuong Method".


### Overdispersion

Der vermutlich häufigste Fall für Count-Daten. 

Kriterien für Overdispersion nach @hilbeModelingCountData2014, p. 41

1. Fehlende explanatorische Prädiktoren
2. Die Daten enthalten Ausreißer
3. Im Modell fehlen Interaktionsterme
4. Ein Prädiktor muss transformiert werden
5. Die Daten sind zu dünn besetzt (*sparse*) (?)
6. Fehlende Werte, die nicht zufällig sind (missing not at random, *MNAR*)

"Test" auf Dispersion: Pearson dispersion, in `R`:

```r
# Model fit
mod <- glm(y ~ x1 + x2 + x3, data = sim, family = poisson(link = "log"))

# Pearson dispersion
sum(resid(mod, type = "pearson")^2) / mod$df.residual
```

Für "echte" Poisson-Modelle ist der Wert 1, und Werte größer bzw. kleiner 1 indizieren over- bzw. underdispersion.

Als Dispersionsstatistik kann die Deviance (*deviance dispersion*) oder oder *pearson dispersion* berechnet werden. Laut @hilbeModelingCountData2014 ist die *Pearson dispersion* zu bevorzugen, da sie für echte Poisson-Modelle gleich 1 ist, wohingegen die *deviance dispersion* nach oben verzerrt ist.

Gründe für overdispersion *kann* zero-inflation sein, allerdings bedeutet das nicht direkt, dass auch ein entsprechendes Modell (ZIP, ZINB...) verwendet werden muss – ggf. lässt sich die overdispersion bereits durch ein NB Modell "auffangen". 

#### Umgang mit Overdispersion {-}

##### Quasipoisson: Skalierung der Standardfehler {-}

$$se(\beta_k) \cdot \sqrt{\chi^2}$$
Wobei $\chi^2$ der Pearson-Dispersionsindex ist (vgl. @hilbeModelingCountData2014, p. 92ff)

In `R` passiert genau das, wenn in `family = quasipoisson()`.

Nachteil: Es wird zuerst ein reguläres Poisson-Modell gefittet, Standardfehler und Dispersionsindex bestimmt, und dann dasselbe Modell mit skalierten Standardfehlern erneut gefittet – dementsprechend ist diese Methode vermutlich für größere Datensätze eher ineffizient.


##### Robuste Varianzschätzer / Sandwich Estimators {-}

Können auch "per default" verwendet werden, da die resultierenden Schätzer im Falle tatsächlich unkorrellierter Daten äquivalent zu den Standardfehlern des Modells sind (i.e. "schadet nicht").

Bootstrapped SEs wiederum erfordern mehr Aufwand, ähneln aber den robusten SEs sowieso sehr stark.



### Underdispersion

Im Kontext von hurdle models taucht folgende Bemerkung auf:

> [...] that underdispersion occurs if zeros are less frequent than the parent distribution would predict.
> The higher the expected value of the Poisson distribution, the lowert the predicted probability of zero outcome and the lower the scope for underdispersion.
> -- [@winkelmannEconometricAnalysisCount2010, p. 180]

Im Allgemeinen wird [generalized Poisson](https://stats.stackexchange.com/a/237177/80056) (R: [`VGAM`](https://rdrr.io/cran/VGAM/man/genpoisson.html)) empfohlen [@hilbeModelingCountData2014].


## Zeros {#zeros}


### Zero Inflation

Problem: "Excess zeros", i.e. die gewählte Dichtefunktion sagt für $P(y_i = 0\ |\ x_i)$ eine deutlich kleinere Wahrscheinlichkeit vor, als in gegebenen Daten tatsächlich vorliegen.


#### Tests auf Zero-Inflation {-}

- Vuong Test (vgl. @perumean-chaneyZeroinflatedOverdispersedWhat2013)
   - Für non-nested models
   - E.g Poisson vs. ZIP
- (Hausman Test)


Für sowohl overdispersion als auch zero-inflation: Score-Tests (?) [@perumean-chaneyZeroinflatedOverdispersedWhat2013, p. 1674, siehe auch entsprechende citations]

> As noted by Yang et al., the univariate situation is recommended for asssessing zero inflation als covariates reduce the power to detect zero inflation
> --- @perumean-chaneyZeroinflatedOverdispersedWhat2013, p. 1674

#### Modellierung {-}

Modellierung via 

- two part hurdle (Siehe Abschnitt \@ref(mod-zi))
- mixture models (Siehe Abschnitt \@ref(mod-hurdle))

[@hilbeModelingCountData2014, p. 19]

Mixtures Models: 
- Zero-inflated poisson (ZIP)
- Zero-inflated negative binomial (ZINB)
- Zero-inflated Poisson Inverse Gaussian (ZPIG)


### Zero Truncation

Wenn die Beobachtungen keine Nullen enthalten bzw. im Modell nicht möglich sind, können *zero-truncated* (ZT) Modelle verwendet werden.

- Zero-truncated Poisson (ZTP)

## Truncation und Censoring {#trunc-cens}

- **Truncation**: Bestimmte counts *nicht möglich*
  - z.B. keine Counts < 5 möglich -> *left truncation* (*right truncation* analog)
  - Interval truncation: Nur counts in Intervall $[a, b]$
- **Censoring**: Bestimmte counts *nicht beobachtet*, aber möglich
